{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82152c78",
   "metadata": {},
   "source": [
    "# Results comparison between Trajectron++ and our method\n",
    "Comparing the results of our method with the Trajectron++ paper's method. The goal of the comparison is to evaluate Trajectron++ on a different dataset than it was trained on to allow more fair comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cfa130bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import dill\n",
    "import json\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import generative_model\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45eb2ea1",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "89f861c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_FDE(pred_x, pred_y, test_x, test_y):\n",
    "\n",
    "    final_displacement_x = pred_x[-1] - test_x[-1]\n",
    "    final_displacement_y = pred_y[-1] - test_y[-1]\n",
    "    FDE = np.sqrt(final_displacement_x**2 + final_displacement_y**2)\n",
    "    \n",
    "    return FDE\n",
    "\n",
    "def calculate_ADE(pred_x, pred_y, test_x, test_y):\n",
    "    total_displacement_error = 0\n",
    "    for point_idx in range(len(test_x)):\n",
    "        displacement_error = np.sqrt((pred_x[point_idx] - test_x[point_idx])**2 + (pred_y[point_idx] - test_y[point_idx])**2)\n",
    "        total_displacement_error += displacement_error\n",
    "\n",
    "    return total_displacement_error/len(pred_x)\n",
    "\n",
    "## The evaluation logic for Trajectron++ loops over the frames and predicts the future trajectories \n",
    "## for each node present in the current frame\n",
    "## Each node has to have at least 7 historical points and 12 future points\n",
    "def get_total_predictable_slices(data):\n",
    "    total_predictable_steps = 0\n",
    "    for i in pd.unique(data.node_id):\n",
    "        #print(len(test[test.node_id == i]))\n",
    "        total_predictable_steps += len(data[data.node_id == i]) - 19\n",
    "    return total_predictable_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73ccb091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(input_data):\n",
    "    data = input_data.copy()\n",
    "    data['frame_id'] = pd.to_numeric(data['frame_id'], downcast='integer')\n",
    "    data['track_id'] = pd.to_numeric(data['track_id'], downcast='integer')\n",
    "\n",
    "    data['frame_id'] = data['frame_id'] // 10\n",
    "\n",
    "    data['frame_id'] -= data['frame_id'].min()\n",
    "\n",
    "    data['node_type'] = 'PEDESTRIAN'\n",
    "    data['node_id'] = data['track_id'].astype(str)\n",
    "    data.sort_values('frame_id', inplace=True)\n",
    "\n",
    "    data['pos_x'] = data['pos_x'] - data['pos_x'].mean()\n",
    "    data['pos_y'] = data['pos_y'] - data['pos_y'].mean()\n",
    "    \n",
    "    # Select only such nodes which have enough data to predict on (7 historical timesteps, 12 future)\n",
    "    v = data.node_id.value_counts()\n",
    "    data = data[data.node_id.isin(v.index[v.gt(19)])]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e398ace7",
   "metadata": {},
   "source": [
    "## Method evaluation logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1a2496f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_our_method(data, params, dataset_title='', single_output = False):\n",
    "    tot = 0\n",
    "    our_fde_best_of = []\n",
    "    our_ade_best_of = []\n",
    "\n",
    "    for frame_id in tqdm(pd.unique(data.frame_id), desc='Ours - ' + dataset_title):\n",
    "\n",
    "        frame_data = data[data.frame_id == frame_id]\n",
    "        #print(frame_data)\n",
    "        for node_id in pd.unique(frame_data.node_id):\n",
    "            # Check if at least 7 historical points are present\n",
    "            # PS: It might be so that the prediction starts at the 8th step instead of 7th? Edited the code to do this at the moment\n",
    "            if len(data[((data.node_id == node_id) & (data.frame_id <= frame_id))]) >= 8:\n",
    "                # Not sure why there has to be more than 12 frames to the future (at least 13) but it's the\n",
    "                # only way to get the number of trajectron++ eval predictions to match up\n",
    "                if len(data[((data.node_id == node_id) & (data.frame_id > frame_id))]) >= 12:\n",
    "                    tot += 1\n",
    "                    node_history_data = data[((data.node_id == node_id) & (data.frame_id <= frame_id) & (data.frame_id >= frame_id-7))]\n",
    "                    node_gt_data = data[((data.node_id == node_id) & (data.frame_id > frame_id) & (data.frame_id <= frame_id+12))]\n",
    "\n",
    "                    x_data = list(node_history_data.pos_x)\n",
    "                    y_data = list(node_history_data.pos_y)\n",
    "                    assert len(x_data) == 8\n",
    "\n",
    "                    x_gt = list(node_gt_data.pos_x)\n",
    "                    y_gt = list(node_gt_data.pos_y)\n",
    "                    assert len(x_gt) == 12\n",
    "\n",
    "                    all_pred_x, all_pred_y, _ = generative_model.predict(x_data, y_data, params, trajectory_length=12)\n",
    "\n",
    "                    best_fde = None\n",
    "                    best_ade = None\n",
    "                    \n",
    "                    if single_output:\n",
    "                        avg_x = np.mean(all_pred_x, axis=0)\n",
    "                        avg_y = np.mean(all_pred_y, axis=0)\n",
    "                        best_fde = calculate_FDE(avg_x, avg_y, x_gt, y_gt)\n",
    "                        best_ade = calculate_ADE(avg_x, avg_y, x_gt, y_gt)\n",
    "                    else:\n",
    "                        for i in range(len(all_pred_x)):\n",
    "                            current_pred_x = all_pred_x[i]\n",
    "                            current_pred_y = all_pred_y[i]\n",
    "\n",
    "                            fde = calculate_FDE(current_pred_x, current_pred_y, x_gt, y_gt)\n",
    "                            if best_fde == None or fde < best_fde:\n",
    "                                best_fde = fde\n",
    "\n",
    "                            ade = calculate_ADE(current_pred_x, current_pred_y, x_gt, y_gt)\n",
    "                            if best_ade == None or ade < best_ade:\n",
    "                                best_ade = ade\n",
    "\n",
    "                    our_fde_best_of.append(best_fde)\n",
    "                    our_ade_best_of.append(best_ade)\n",
    "                    \n",
    "    return our_fde_best_of, our_ade_best_of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4e2101a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cvm_with_scenarios(data, dataset_title='', history_length=8):\n",
    "    tot = 0\n",
    "    our_fde_best_of = []\n",
    "    our_ade_best_of = []\n",
    "\n",
    "    for frame_id in tqdm(pd.unique(data.frame_id), desc='CVM - ' + dataset_title):\n",
    "\n",
    "        frame_data = data[data.frame_id == frame_id]\n",
    "        #print(frame_data)\n",
    "        for node_id in pd.unique(frame_data.node_id):\n",
    "            # Check if at least 7 historical points are present\n",
    "            # PS: It might be so that the prediction starts at the 8th step instead of 7th? Edited the code to do this at the moment\n",
    "            if len(data[((data.node_id == node_id) & (data.frame_id <= frame_id))]) >= 8:\n",
    "                # Not sure why there has to be more than 12 frames to the future (at least 13) but it's the\n",
    "                # only way to get the number of trajectron++ eval predictions to match up\n",
    "                if len(data[((data.node_id == node_id) & (data.frame_id > frame_id))]) >= 12:\n",
    "                    tot += 1\n",
    "                    node_history_data = data[((data.node_id == node_id) & (data.frame_id <= frame_id) & (data.frame_id >= frame_id-7))]\n",
    "                    node_gt_data = data[((data.node_id == node_id) & (data.frame_id > frame_id) & (data.frame_id <= frame_id+12))]\n",
    "\n",
    "                    x_data = list(node_history_data.pos_x)\n",
    "                    y_data = list(node_history_data.pos_y)\n",
    "                    assert len(x_data) == 8\n",
    "\n",
    "                    x_gt = list(node_gt_data.pos_x)\n",
    "                    y_gt = list(node_gt_data.pos_y)\n",
    "                    assert len(x_gt) == 12\n",
    "\n",
    "                    all_pred_x, all_pred_y = [], []\n",
    "                    \n",
    "                    # CVM\n",
    "                    for i in range(20):\n",
    "                        history_x = x_data[-history_length:]\n",
    "                        history_y = y_data[-history_length:]\n",
    "                        assert len(history_x) == history_length\n",
    "                        \n",
    "                        if i == 0:\n",
    "                            vel_x = [history_x[i] - history_x[i-1] for i in range(1, len(history_x))]\n",
    "                            vel_y = [history_y[i] - history_y[i-1] for i in range(1, len(history_y))]\n",
    "                        else:\n",
    "                            vel_x = [(history_x[i] - history_x[i-1]) + np.random.normal(0, 1) for i in range(1, len(history_x))]\n",
    "                            vel_y = [(history_y[i] - history_y[i-1]) + np.random.normal(0, 1) for i in range(1, len(history_y))]\n",
    "                        \n",
    "                        assert len(vel_x) == history_length-1\n",
    "                        avg_vel_x = np.mean(vel_x)\n",
    "                        avg_vel_y = np.mean(vel_y)\n",
    "                        \n",
    "                        pred_x = [x_data[-1] + i*avg_vel_x for i in range(1, 13)]\n",
    "                        pred_y = [y_data[-1] + i*avg_vel_y for i in range(1, 13)]\n",
    "                        assert len(pred_x) == 12\n",
    "                        \n",
    "                        all_pred_x.append(pred_x)\n",
    "                        all_pred_y.append(pred_y)\n",
    "                    \n",
    "\n",
    "                    best_fde = None\n",
    "                    best_ade = None\n",
    "                    for i in range(len(all_pred_x)):\n",
    "                        current_pred_x = all_pred_x[i]\n",
    "                        current_pred_y = all_pred_y[i]\n",
    "\n",
    "                        fde = calculate_FDE(current_pred_x, current_pred_y, x_gt, y_gt)\n",
    "                        if best_fde == None or fde < best_fde:\n",
    "                            best_fde = fde\n",
    "\n",
    "                        ade = calculate_ADE(current_pred_x, current_pred_y, x_gt, y_gt)\n",
    "                        if best_ade == None or ade < best_ade:\n",
    "                            best_ade = ade\n",
    "\n",
    "                    our_fde_best_of.append(best_fde)\n",
    "                    our_ade_best_of.append(best_ade)\n",
    "                    \n",
    "    return our_fde_best_of, our_ade_best_of"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f8687e",
   "metadata": {},
   "source": [
    "## Automated results comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "692d414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_eth = {\n",
    "    \"NOISE\": 0.05,\n",
    "    \"NO_OF_TRAJECTORIES\": 1000,\n",
    "    \"CONST_VEL_MODEL_PROB\": 0.8,\n",
    "\n",
    "    \"STOP_PROB\": 0.05,\n",
    "\n",
    "    \"DISCOUNT_AVG_PROB\": 0.5,\n",
    "    \"DISCOUNT_LOWER_BOUND\": 0.5,\n",
    "\n",
    "    \"VELOCITY_CHANGE_PROB\": 0.2,\n",
    "    \"VELOCITY_CHANGE_NOISE\": 0.1,\n",
    "\n",
    "    \"ANGLE_CHANGE_PROB\": 0.2,\n",
    "    \"ANGLE_CHANGE_NOISE\": 1,\n",
    "\n",
    "    \"GROUP_PERCENTAGES\": [0.15, 0.68, 0.95, 1.0],\n",
    "    \"GROUP_CLUSTER_COUNT\": [1, 7, 7, 5] # Total 20 traj\n",
    "}\n",
    "\n",
    "params_rest = {\n",
    "    \"NOISE\": 0.05,\n",
    "    \"NO_OF_TRAJECTORIES\": 1000,\n",
    "    \"CONST_VEL_MODEL_PROB\": 0.9,\n",
    "\n",
    "    \"STOP_PROB\": 0.05,\n",
    "\n",
    "    \"DISCOUNT_AVG_PROB\": 0.5,\n",
    "    \"DISCOUNT_LOWER_BOUND\": 0.5,\n",
    "\n",
    "    \"VELOCITY_CHANGE_PROB\": 0.15,\n",
    "    \"VELOCITY_CHANGE_NOISE\": 0.1,\n",
    "\n",
    "    \"ANGLE_CHANGE_PROB\": 0.1,\n",
    "    \"ANGLE_CHANGE_NOISE\": 1,\n",
    "\n",
    "    \"GROUP_PERCENTAGES\": [0.25, 0.68, 0.95, 1.0],\n",
    "    \"GROUP_CLUSTER_COUNT\": [2, 7, 6, 5] # Total 20 traj\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "de614915",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_method_params = [params_eth, params_eth, params_rest, params_rest]\n",
    "\n",
    "files = [\n",
    "    'eth/test/biwi_eth.txt', \n",
    "    'hotel/test/biwi_hotel.txt', \n",
    "    'zara1/test/crowds_zara01.txt', \n",
    "    'zara2/test/crowds_zara02.txt'\n",
    "]\n",
    "\n",
    "trajectron_resultset_names = [\n",
    "    'eth_vel_12', \n",
    "    'hotel_vel', \n",
    "    'zara1_vel', \n",
    "    'zara2_vel'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2538a318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all_datasets(our_method_params, files, trajectron_resultset_names):\n",
    "    base_path = './pedestrians/raw/'\n",
    "\n",
    "    ours_results = {'BEST_OF_20': {'FDE': [], 'ADE': []}, 'MOST_LIKELY': {'FDE': [], 'ADE': []}}\n",
    "    trajectron_results = {'BEST_OF_20': {'FDE': [], 'ADE': []}, 'MOST_LIKELY': {'FDE': [], 'ADE': []}}\n",
    "    cvm_long_results = {'BEST_OF_20': {'FDE': [], 'ADE': []}, 'MOST_LIKELY': {'FDE': [], 'ADE': []}}\n",
    "    cvm_short_results = {'BEST_OF_20': {'FDE': [], 'ADE': []}, 'MOST_LIKELY': {'FDE': [], 'ADE': []}}\n",
    "\n",
    "    for file_idx, file in enumerate(files):\n",
    "        data = pd.read_csv(base_path + file, sep='\\t', index_col=False, header=None)\n",
    "        data.columns = ['frame_id', 'track_id', 'pos_x', 'pos_y']\n",
    "\n",
    "        data = process_data(data)\n",
    "\n",
    "        num_predictable_trajectories = get_total_predictable_slices(data)\n",
    "\n",
    "        ## Trajectron\n",
    "        trajectron_fde = []\n",
    "        with open('pedestrians/results/' + trajectron_resultset_names[file_idx] + '_fde_best_of.csv', mode='r') as csv_file:\n",
    "            csv_reader = csv.DictReader(csv_file)\n",
    "            line_count = 0\n",
    "            for row in csv_reader:\n",
    "                trajectron_fde.append(float(row['value']))\n",
    "\n",
    "        trajectron_ade = []\n",
    "        with open('pedestrians/results/' + trajectron_resultset_names[file_idx] + '_ade_best_of.csv', mode='r') as csv_file:\n",
    "            csv_reader = csv.DictReader(csv_file)\n",
    "            line_count = 0\n",
    "            for row in csv_reader:\n",
    "                trajectron_ade.append(float(row['value']))\n",
    "\n",
    "        trajectron_results['BEST_OF_20']['FDE'].append(np.mean(trajectron_fde))\n",
    "        trajectron_results['BEST_OF_20']['ADE'].append(np.mean(trajectron_ade))\n",
    "\n",
    "        # make sure that there is no discrepancy between our data processing and trajectron evaluation results size\n",
    "        assert len(trajectron_fde) == num_predictable_trajectories\n",
    "        assert len(trajectron_ade) == num_predictable_trajectories\n",
    "\n",
    "        ## Ours\n",
    "        our_fde_best_of_20, our_ade_best_of_20 = evaluate_our_method(data, our_method_params[file_idx], dataset_title=trajectron_resultset_names[file_idx])\n",
    "        ours_results['BEST_OF_20']['FDE'].append(np.mean(our_fde_best_of_20))\n",
    "        ours_results['BEST_OF_20']['ADE'].append(np.mean(our_ade_best_of_20))\n",
    "\n",
    "        ## CVM\n",
    "        cvm_fde_best_of, cvm_ade_best_of = evaluate_cvm_with_scenarios(data, dataset_title=trajectron_resultset_names[file_idx])\n",
    "        cvm_fde_short_history_best_of, cvm_ade_short_history_best_of = evaluate_cvm_with_scenarios(data, dataset_title=trajectron_resultset_names[file_idx], history_length=2)\n",
    "        cvm_long_results['BEST_OF_20']['FDE'].append(np.mean(cvm_fde_best_of))\n",
    "        cvm_long_results['BEST_OF_20']['ADE'].append(np.mean(cvm_ade_best_of))\n",
    "        cvm_short_results['BEST_OF_20']['FDE'].append(np.mean(cvm_fde_short_history_best_of))\n",
    "        cvm_short_results['BEST_OF_20']['ADE'].append(np.mean(cvm_ade_short_history_best_of))\n",
    "    \n",
    "    \n",
    "    ## Univ is a separate case as it has 2 scenes\n",
    "    filename1 = './pedestrians/raw/univ/test/students001.txt'\n",
    "    filename2 = './pedestrians/raw/univ/test/students003.txt'\n",
    "    univ_data_1 = pd.read_csv(filename1, sep='\\t', index_col=False, header=None)\n",
    "    univ_data_2 = pd.read_csv(filename2, sep='\\t', index_col=False, header=None)\n",
    "    univ_data_1.columns = ['frame_id', 'track_id', 'pos_x', 'pos_y']\n",
    "    univ_data_2.columns = ['frame_id', 'track_id', 'pos_x', 'pos_y']\n",
    "\n",
    "    univ_data_1 = process_data(univ_data_1)\n",
    "    univ_data_2 = process_data(univ_data_2)\n",
    "\n",
    "    ## Ours\n",
    "    our_fde_best_of_1, our_ade_best_of_1 = evaluate_our_method(univ_data_1, params_rest, dataset_title='univ 1')\n",
    "    our_fde_best_of_2, our_ade_best_of_2 = evaluate_our_method(univ_data_2, params_rest, dataset_title='univ 2')\n",
    "\n",
    "    our_fde_best_of_20 = our_fde_best_of_1 + our_fde_best_of_2\n",
    "    our_ade_best_of_20 = our_ade_best_of_1 + our_ade_best_of_2\n",
    "\n",
    "    ours_results['BEST_OF_20']['FDE'].append(np.mean(our_fde_best_of_20))\n",
    "    ours_results['BEST_OF_20']['ADE'].append(np.mean(our_ade_best_of_20))\n",
    "\n",
    "    ## CVM\n",
    "    cvm_fde_best_of_1, cvm_ade_best_of_1 = evaluate_cvm_with_scenarios(univ_data_1, dataset_title='univ 1')\n",
    "    cvm_fde_best_of_2, cvm_ade_best_of_2 = evaluate_cvm_with_scenarios(univ_data_2, dataset_title='univ 2')\n",
    "\n",
    "    cvm_fde_best_of = cvm_fde_best_of_1 + cvm_fde_best_of_2\n",
    "    cvm_ade_best_of = cvm_ade_best_of_1 + cvm_ade_best_of_2\n",
    "\n",
    "    cvm_fde_short_hist_best_of_1, cvm_ade_short_hist_best_of_1 = evaluate_cvm_with_scenarios(univ_data_1, dataset_title='univ 1', history_length=2)\n",
    "    cvm_fde_short_hist_best_of_2, cvm_ade_short_hist_best_of_2 = evaluate_cvm_with_scenarios(univ_data_2, dataset_title='univ 2', history_length=2)\n",
    "\n",
    "    cvm_fde_short_history_best_of = cvm_fde_short_hist_best_of_1 + cvm_fde_short_hist_best_of_2\n",
    "    cvm_ade_short_history_best_of = cvm_ade_short_hist_best_of_1 + cvm_ade_short_hist_best_of_2\n",
    "\n",
    "    cvm_long_results['BEST_OF_20']['FDE'].append(np.mean(cvm_fde_best_of))\n",
    "    cvm_long_results['BEST_OF_20']['ADE'].append(np.mean(cvm_ade_best_of))\n",
    "    cvm_short_results['BEST_OF_20']['FDE'].append(np.mean(cvm_fde_short_history_best_of))\n",
    "    cvm_short_results['BEST_OF_20']['ADE'].append(np.mean(cvm_ade_short_history_best_of))\n",
    "\n",
    "    ## Trajectron\n",
    "    trajectron_fde = []\n",
    "    with open('pedestrians/results/univ_vel_fde_best_of.csv', mode='r') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            trajectron_fde.append(float(row['value']))\n",
    "\n",
    "    trajectron_ade = []\n",
    "    with open('pedestrians/results/univ_vel_ade_best_of.csv', mode='r') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            trajectron_ade.append(float(row['value']))\n",
    "\n",
    "    trajectron_results['BEST_OF_20']['FDE'].append(np.mean(trajectron_fde))\n",
    "    trajectron_results['BEST_OF_20']['ADE'].append(np.mean(trajectron_ade))\n",
    "    \n",
    "    return [\n",
    "        ours_results,\n",
    "        trajectron_results,\n",
    "        cvm_long_results,\n",
    "        cvm_short_results\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641fec72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ours - eth_vel_12: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 484/484 [01:05<00:00,  7.37it/s]\n",
      "CVM - eth_vel_12: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 484/484 [00:01<00:00, 379.80it/s]\n",
      "CVM - eth_vel_12: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 484/484 [00:00<00:00, 493.55it/s]\n",
      "Ours - hotel_vel: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 913/913 [03:24<00:00,  4.47it/s]\n",
      "CVM - hotel_vel: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 913/913 [00:04<00:00, 218.11it/s]\n",
      "CVM - hotel_vel: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 913/913 [00:03<00:00, 245.53it/s]\n",
      "Ours - zara1_vel: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 864/864 [06:07<00:00,  2.35it/s]\n",
      "CVM - zara1_vel: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 864/864 [00:08<00:00, 103.22it/s]\n",
      "CVM - zara1_vel: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 864/864 [00:07<00:00, 119.05it/s]\n",
      "Ours - zara2_vel: 100%|█████████████████████████████████████████████████████████████████████████████████████████| 1052/1052 [15:38<00:00,  1.12it/s]\n",
      "CVM - zara2_vel: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 1052/1052 [00:23<00:00, 44.24it/s]\n",
      "CVM - zara2_vel: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 1052/1052 [00:21<00:00, 48.24it/s]\n",
      "Ours - univ 1:  12%|███████████▎                                                                                   | 53/444 [05:21<59:25,  9.12s/it]"
     ]
    }
   ],
   "source": [
    "res = evaluate_all_datasets(our_method_params, files, trajectron_resultset_names)\n",
    "\n",
    "ours_results = res[0]\n",
    "trajectron_results = res[1]\n",
    "cvm_long_results = res[2]\n",
    "cvm_short_results = res[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8291fdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [\n",
    "    'ETH', \n",
    "    'Hotel', \n",
    "    'Zara 1', \n",
    "    'Zara 2',\n",
    "    'Univ'\n",
    "]\n",
    "\n",
    "df_data_fde = {\n",
    "    'CVM (8pt history)' : pd.Series(cvm_long_results['BEST_OF_20']['FDE'], index = index),\n",
    "    'CVM (2pt history)' : pd.Series(cvm_short_results['BEST_OF_20']['FDE'], index = index),\n",
    "    'Trajectron++' : pd.Series(trajectron_results['BEST_OF_20']['FDE'], index = index),\n",
    "    'Ours': pd.Series(ours_results['BEST_OF_20']['FDE'], index = index)\n",
    "}\n",
    "\n",
    "df_fde = pd.DataFrame(df_data_fde)\n",
    "\n",
    "df_data_ade = {\n",
    "    'CVM (8pt history)' : pd.Series(cvm_long_results['BEST_OF_20']['ADE'], index = index),\n",
    "    'CVM (2pt history)' : pd.Series(cvm_short_results['BEST_OF_20']['ADE'], index = index),\n",
    "    'Trajectron++' : pd.Series(trajectron_results['BEST_OF_20']['ADE'], index = index),\n",
    "    'Ours': pd.Series(ours_results['BEST_OF_20']['ADE'], index = index)\n",
    "}\n",
    "\n",
    "df_ade = pd.DataFrame(df_data_ade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "02c850c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d4fb0_row0_col3, #T_d4fb0_row1_col3, #T_d4fb0_row2_col2, #T_d4fb0_row3_col2, #T_d4fb0_row4_col2 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d4fb0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d4fb0_level0_col0\" class=\"col_heading level0 col0\" >CVM (8pt history)</th>\n",
       "      <th id=\"T_d4fb0_level0_col1\" class=\"col_heading level0 col1\" >CVM (2pt history)</th>\n",
       "      <th id=\"T_d4fb0_level0_col2\" class=\"col_heading level0 col2\" >Trajectron++</th>\n",
       "      <th id=\"T_d4fb0_level0_col3\" class=\"col_heading level0 col3\" >Ours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d4fb0_level0_row0\" class=\"row_heading level0 row0\" >ETH</th>\n",
       "      <td id=\"T_d4fb0_row0_col0\" class=\"data row0 col0\" >1.119766</td>\n",
       "      <td id=\"T_d4fb0_row0_col1\" class=\"data row0 col1\" >1.768382</td>\n",
       "      <td id=\"T_d4fb0_row0_col2\" class=\"data row0 col2\" >0.918525</td>\n",
       "      <td id=\"T_d4fb0_row0_col3\" class=\"data row0 col3\" >0.892368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4fb0_level0_row1\" class=\"row_heading level0 row1\" >Hotel</th>\n",
       "      <td id=\"T_d4fb0_row1_col0\" class=\"data row1 col0\" >0.366464</td>\n",
       "      <td id=\"T_d4fb0_row1_col1\" class=\"data row1 col1\" >0.571324</td>\n",
       "      <td id=\"T_d4fb0_row1_col2\" class=\"data row1 col2\" >0.273470</td>\n",
       "      <td id=\"T_d4fb0_row1_col3\" class=\"data row1 col3\" >0.264365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4fb0_level0_row2\" class=\"row_heading level0 row2\" >Zara 1</th>\n",
       "      <td id=\"T_d4fb0_row2_col0\" class=\"data row2 col0\" >0.796770</td>\n",
       "      <td id=\"T_d4fb0_row2_col1\" class=\"data row2 col1\" >0.881716</td>\n",
       "      <td id=\"T_d4fb0_row2_col2\" class=\"data row2 col2\" >0.399671</td>\n",
       "      <td id=\"T_d4fb0_row2_col3\" class=\"data row2 col3\" >0.509057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4fb0_level0_row3\" class=\"row_heading level0 row3\" >Zara 2</th>\n",
       "      <td id=\"T_d4fb0_row3_col0\" class=\"data row3 col0\" >0.555702</td>\n",
       "      <td id=\"T_d4fb0_row3_col1\" class=\"data row3 col1\" >0.654918</td>\n",
       "      <td id=\"T_d4fb0_row3_col2\" class=\"data row3 col2\" >0.313920</td>\n",
       "      <td id=\"T_d4fb0_row3_col3\" class=\"data row3 col3\" >0.413604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4fb0_level0_row4\" class=\"row_heading level0 row4\" >Univ</th>\n",
       "      <td id=\"T_d4fb0_row4_col0\" class=\"data row4 col0\" >0.887809</td>\n",
       "      <td id=\"T_d4fb0_row4_col1\" class=\"data row4 col1\" >1.058825</td>\n",
       "      <td id=\"T_d4fb0_row4_col2\" class=\"data row4 col2\" >0.545510</td>\n",
       "      <td id=\"T_d4fb0_row4_col3\" class=\"data row4 col3\" >0.582854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2894ae670>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_fde\n",
    "df_fde.style.highlight_min(color = 'lightgreen', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fb95dbb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_83a0a_row0_col2, #T_83a0a_row1_col3, #T_83a0a_row2_col2, #T_83a0a_row3_col2, #T_83a0a_row4_col2 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_83a0a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_83a0a_level0_col0\" class=\"col_heading level0 col0\" >CVM (8pt history)</th>\n",
       "      <th id=\"T_83a0a_level0_col1\" class=\"col_heading level0 col1\" >CVM (2pt history)</th>\n",
       "      <th id=\"T_83a0a_level0_col2\" class=\"col_heading level0 col2\" >Trajectron++</th>\n",
       "      <th id=\"T_83a0a_level0_col3\" class=\"col_heading level0 col3\" >Ours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_83a0a_level0_row0\" class=\"row_heading level0 row0\" >ETH</th>\n",
       "      <td id=\"T_83a0a_row0_col0\" class=\"data row0 col0\" >0.654488</td>\n",
       "      <td id=\"T_83a0a_row0_col1\" class=\"data row0 col1\" >0.897325</td>\n",
       "      <td id=\"T_83a0a_row0_col2\" class=\"data row0 col2\" >0.534569</td>\n",
       "      <td id=\"T_83a0a_row0_col3\" class=\"data row0 col3\" >0.562136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83a0a_level0_row1\" class=\"row_heading level0 row1\" >Hotel</th>\n",
       "      <td id=\"T_83a0a_row1_col0\" class=\"data row1 col0\" >0.205606</td>\n",
       "      <td id=\"T_83a0a_row1_col1\" class=\"data row1 col1\" >0.300796</td>\n",
       "      <td id=\"T_83a0a_row1_col2\" class=\"data row1 col2\" >0.173194</td>\n",
       "      <td id=\"T_83a0a_row1_col3\" class=\"data row1 col3\" >0.162743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83a0a_level0_row2\" class=\"row_heading level0 row2\" >Zara 1</th>\n",
       "      <td id=\"T_83a0a_row2_col0\" class=\"data row2 col0\" >0.415939</td>\n",
       "      <td id=\"T_83a0a_row2_col1\" class=\"data row2 col1\" >0.406821</td>\n",
       "      <td id=\"T_83a0a_row2_col2\" class=\"data row2 col2\" >0.210878</td>\n",
       "      <td id=\"T_83a0a_row2_col3\" class=\"data row2 col3\" >0.304891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83a0a_level0_row3\" class=\"row_heading level0 row3\" >Zara 2</th>\n",
       "      <td id=\"T_83a0a_row3_col0\" class=\"data row3 col0\" >0.294794</td>\n",
       "      <td id=\"T_83a0a_row3_col1\" class=\"data row3 col1\" >0.303181</td>\n",
       "      <td id=\"T_83a0a_row3_col2\" class=\"data row3 col2\" >0.162733</td>\n",
       "      <td id=\"T_83a0a_row3_col3\" class=\"data row3 col3\" >0.247927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83a0a_level0_row4\" class=\"row_heading level0 row4\" >Univ</th>\n",
       "      <td id=\"T_83a0a_row4_col0\" class=\"data row4 col0\" >0.475241</td>\n",
       "      <td id=\"T_83a0a_row4_col1\" class=\"data row4 col1\" >0.492425</td>\n",
       "      <td id=\"T_83a0a_row4_col2\" class=\"data row4 col2\" >0.278476</td>\n",
       "      <td id=\"T_83a0a_row4_col3\" class=\"data row4 col3\" >0.353319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x289b07730>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ade.style.highlight_min(color = 'lightgreen', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0907152",
   "metadata": {},
   "source": [
    "### Testing with an additional group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745a8407",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_eth = {\n",
    "    \"NOISE\": 0.05,\n",
    "    \"NO_OF_TRAJECTORIES\": 1000,\n",
    "    \"CONST_VEL_MODEL_PROB\": 0.8,\n",
    "\n",
    "    \"STOP_PROB\": 0.05,\n",
    "\n",
    "    \"DISCOUNT_AVG_PROB\": 0.5,\n",
    "    \"DISCOUNT_LOWER_BOUND\": 0.5,\n",
    "\n",
    "    \"VELOCITY_CHANGE_PROB\": 0.2,\n",
    "    \"VELOCITY_CHANGE_NOISE\": 0.1,\n",
    "\n",
    "    \"ANGLE_CHANGE_PROB\": 0.2,\n",
    "    \"ANGLE_CHANGE_NOISE\": 1,\n",
    "\n",
    "    \"GROUP_PERCENTAGES\": [0.15, 0.40, 0.68, 0.95, 1.0],\n",
    "    \"GROUP_CLUSTER_COUNT\": [1, 6, 5, 5, 3] # Total 20 traj\n",
    "}\n",
    "\n",
    "params_rest = {\n",
    "    \"NOISE\": 0.05,\n",
    "    \"NO_OF_TRAJECTORIES\": 1000,\n",
    "    \"CONST_VEL_MODEL_PROB\": 0.9,\n",
    "\n",
    "    \"STOP_PROB\": 0.05,\n",
    "\n",
    "    \"DISCOUNT_AVG_PROB\": 0.5,\n",
    "    \"DISCOUNT_LOWER_BOUND\": 0.5,\n",
    "\n",
    "    \"VELOCITY_CHANGE_PROB\": 0.15,\n",
    "    \"VELOCITY_CHANGE_NOISE\": 0.1,\n",
    "\n",
    "    \"ANGLE_CHANGE_PROB\": 0.1,\n",
    "    \"ANGLE_CHANGE_NOISE\": 1,\n",
    "\n",
    "    \"GROUP_PERCENTAGES\": [0.15, 0.40, 0.68, 0.95, 1.0],\n",
    "    \"GROUP_CLUSTER_COUNT\": [1, 6, 5, 5, 3] # Total 20 traj\n",
    "}\n",
    "\n",
    "res = evaluate_all_datasets(our_method_params, files, trajectron_resultset_names)\n",
    "\n",
    "ours_results = res[0]\n",
    "trajectron_results = res[1]\n",
    "cvm_long_results = res[2]\n",
    "cvm_short_results = res[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d43d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [\n",
    "    'ETH', \n",
    "    'Hotel', \n",
    "    'Zara 1', \n",
    "    'Zara 2',\n",
    "    'Univ'\n",
    "]\n",
    "\n",
    "df_data_fde = {\n",
    "    'CVM (8pt history)' : pd.Series(cvm_long_results['BEST_OF_20']['FDE'], index = index),\n",
    "    'CVM (2pt history)' : pd.Series(cvm_short_results['BEST_OF_20']['FDE'], index = index),\n",
    "    'Trajectron++' : pd.Series(trajectron_results['BEST_OF_20']['FDE'], index = index),\n",
    "    'Ours': pd.Series(ours_results['BEST_OF_20']['FDE'], index = index)\n",
    "}\n",
    "\n",
    "df_fde = pd.DataFrame(df_data_fde)\n",
    "\n",
    "df_data_ade = {\n",
    "    'CVM (8pt history)' : pd.Series(cvm_long_results['BEST_OF_20']['ADE'], index = index),\n",
    "    'CVM (2pt history)' : pd.Series(cvm_short_results['BEST_OF_20']['ADE'], index = index),\n",
    "    'Trajectron++' : pd.Series(trajectron_results['BEST_OF_20']['ADE'], index = index),\n",
    "    'Ours': pd.Series(ours_results['BEST_OF_20']['ADE'], index = index)\n",
    "}\n",
    "\n",
    "df_ade = pd.DataFrame(df_data_ade)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
