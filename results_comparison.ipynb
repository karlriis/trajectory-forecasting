{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d1740c3",
   "metadata": {},
   "source": [
    "# Results comparison between Trajectron++, the constant velocity model, and our method\n",
    "Comparing the results of our method with the Trajectron++ paper's method and the constant velocity model.  \n",
    "\n",
    "Our method and the CVM are evaluated live in this notebook.\n",
    "\n",
    "Trajectron++ was trained and evaluated separately, the results reside in './trajectron++/results'. It was trained per the instructions in their repository: https://github.com/StanfordASL/Trajectron-plus-plus/tree/eccv2020. If needed then it can be trained and evaluated following their instructions again, the results should be copied to the same folder to make use of the new results. The data for evaluating our method is taken from the repository as well, this resides in './trajectron++/data'.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfa130bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import generative_model\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dd1a8c",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ac04490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_FDE(pred_x, pred_y, test_x, test_y):\n",
    "\n",
    "    final_displacement_x = pred_x[-1] - test_x[-1]\n",
    "    final_displacement_y = pred_y[-1] - test_y[-1]\n",
    "    FDE = np.sqrt(final_displacement_x**2 + final_displacement_y**2)\n",
    "    \n",
    "    return FDE\n",
    "\n",
    "def calculate_ADE(pred_x, pred_y, test_x, test_y):\n",
    "    assert len(pred_x) == len(test_x)\n",
    "    total_displacement_error = 0\n",
    "    for point_idx in range(len(test_x)):\n",
    "        displacement_error = np.sqrt((pred_x[point_idx] - test_x[point_idx])**2 + (pred_y[point_idx] - test_y[point_idx])**2)\n",
    "        total_displacement_error += displacement_error\n",
    "\n",
    "    return total_displacement_error/len(pred_x)\n",
    "\n",
    "## The evaluation logic for Trajectron++ loops over the frames and predicts the future trajectories \n",
    "## for each pedestrian present in the current frame.\n",
    "## Each node/pedestrian has to have at least 8 historical points and 12 future points.\n",
    "def get_total_predictable_slices(data):\n",
    "    total_predictable_steps = 0\n",
    "    for i in pd.unique(data.node_id):\n",
    "        total_predictable_steps += len(data[data.node_id == i]) - 19\n",
    "    return total_predictable_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "907d43d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(input_data):\n",
    "    data = input_data.copy()\n",
    "    data['frame_id'] = pd.to_numeric(data['frame_id'], downcast='integer')\n",
    "    data['track_id'] = pd.to_numeric(data['track_id'], downcast='integer')\n",
    "\n",
    "    data['frame_id'] = data['frame_id'] // 10\n",
    "\n",
    "    data['frame_id'] -= data['frame_id'].min()\n",
    "\n",
    "    data['node_type'] = 'PEDESTRIAN'\n",
    "    data['node_id'] = data['track_id'].astype(str)\n",
    "    data.sort_values('frame_id', inplace=True)\n",
    "\n",
    "    data['pos_x'] = data['pos_x'] - data['pos_x'].mean()\n",
    "    data['pos_y'] = data['pos_y'] - data['pos_y'].mean()\n",
    "    \n",
    "    # Select only such nodes which have enough data to predict on (8 historical timesteps, 12 future)\n",
    "    v = data.node_id.value_counts()\n",
    "    data = data[data.node_id.isin(v.index[v.gt(19)])]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce140413",
   "metadata": {},
   "source": [
    "## Method evaluation logic\n",
    "Logic for evaluating our method and the CVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46e27d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_our_method(data, params, dataset_title='', clustering_method='KMeans', smoothing=False):\n",
    "    our_fde_best_of = []\n",
    "    our_ade_best_of = []\n",
    "    our_fde_single = []\n",
    "    our_ade_single = []\n",
    "\n",
    "    # Loop over the dataset frame by frame\n",
    "    for frame_id in tqdm(pd.unique(data.frame_id), desc='Ours - ' + dataset_title):\n",
    "\n",
    "        frame_data = data[data.frame_id == frame_id]\n",
    "        \n",
    "        # Loop over all agents in the current frame\n",
    "        for node_id in pd.unique(frame_data.node_id):\n",
    "            # Check for 8 points of history for current agent\n",
    "            if len(data[((data.node_id == node_id) & (data.frame_id <= frame_id))]) >= 8:\n",
    "                # Check for 12 points of future for current agent\n",
    "                if len(data[((data.node_id == node_id) & (data.frame_id > frame_id))]) >= 12:\n",
    "                    node_history_data = data[((data.node_id == node_id) & (data.frame_id <= frame_id) & (data.frame_id >= frame_id-7))]\n",
    "                    node_gt_data = data[((data.node_id == node_id) & (data.frame_id > frame_id) & (data.frame_id <= frame_id+12))]\n",
    "\n",
    "                    x_data = list(node_history_data.pos_x)\n",
    "                    y_data = list(node_history_data.pos_y)\n",
    "                    assert len(x_data) == 8\n",
    "\n",
    "                    x_gt = list(node_gt_data.pos_x)\n",
    "                    y_gt = list(node_gt_data.pos_y)\n",
    "                    assert len(x_gt) == 12\n",
    "\n",
    "                    all_pred_x, all_pred_y, weights = generative_model.predict(x_data, y_data, params, trajectory_length=12, clustering_method=clustering_method, smoothing=smoothing)\n",
    "                    assert len(all_pred_x[0]) == 12\n",
    "                    \n",
    "                    # This section is for producing a single trajectory\n",
    "                    # Choose the first prediction (i.e. the most likely one)\n",
    "                    single_x = all_pred_x[0]\n",
    "                    single_y = all_pred_y[0]\n",
    "\n",
    "                    single_fde = calculate_FDE(single_x, single_y, x_gt, y_gt)\n",
    "                    single_ade = calculate_ADE(single_x, single_y, x_gt, y_gt)\n",
    "                    our_fde_single.append(single_fde)\n",
    "                    our_ade_single.append(single_ade)\n",
    "                        \n",
    "                        \n",
    "                    # This section is for finding the best trajectories out of many in terms of FDE and ADE\n",
    "                    best_fde = None\n",
    "                    best_ade = None\n",
    "\n",
    "                    for i in range(len(all_pred_x)):\n",
    "                        current_pred_x = all_pred_x[i]\n",
    "                        current_pred_y = all_pred_y[i]\n",
    "\n",
    "                        fde = calculate_FDE(current_pred_x, current_pred_y, x_gt, y_gt)\n",
    "                        if best_fde == None or fde < best_fde:\n",
    "                            best_fde = fde\n",
    "\n",
    "                        ade = calculate_ADE(current_pred_x, current_pred_y, x_gt, y_gt)\n",
    "                        if best_ade == None or ade < best_ade:\n",
    "                            best_ade = ade\n",
    "\n",
    "                    our_fde_best_of.append(best_fde)\n",
    "                    our_ade_best_of.append(best_ade)\n",
    "                    \n",
    "    return our_fde_best_of, our_ade_best_of, our_fde_single, our_ade_single\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "781a48eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluates CVM with scenarios \n",
    "# i.e. the CVM is run multiple times for one historical trajectory to attain many future predictions\n",
    "# (variance is introduced by adding noise to the historical trajectory for each run)\n",
    "def evaluate_cvm_with_scenarios(data, dataset_title='', history_length=8):\n",
    "    # parameter history_length tells the CVM how many points of history it will use for \n",
    "    # calculating the constant velocity used for prediction\n",
    "    \n",
    "    cvm_fde_best_of = []\n",
    "    cvm_ade_best_of = []  \n",
    "    cvm_fde_single = []\n",
    "    cvm_ade_single = []\n",
    "\n",
    "    for frame_id in tqdm(pd.unique(data.frame_id), desc='CVM - ' + dataset_title):\n",
    "        frame_data = data[data.frame_id == frame_id]\n",
    "        for node_id in pd.unique(frame_data.node_id):\n",
    "            # Check if at least 8 historical points are present\n",
    "            if len(data[((data.node_id == node_id) & (data.frame_id <= frame_id))]) >= 8:\n",
    "                # Check if at least 12 future points are present\n",
    "                if len(data[((data.node_id == node_id) & (data.frame_id > frame_id))]) >= 12:\n",
    "                    node_history_data = data[((data.node_id == node_id) & (data.frame_id <= frame_id) & (data.frame_id >= frame_id-7))]\n",
    "                    node_gt_data = data[((data.node_id == node_id) & (data.frame_id > frame_id) & (data.frame_id <= frame_id+12))]\n",
    "\n",
    "                    x_data = list(node_history_data.pos_x)\n",
    "                    y_data = list(node_history_data.pos_y)\n",
    "                    assert len(x_data) == 8\n",
    "\n",
    "                    x_gt = list(node_gt_data.pos_x)\n",
    "                    y_gt = list(node_gt_data.pos_y)\n",
    "                    assert len(x_gt) == 12\n",
    "\n",
    "                    all_pred_x, all_pred_y = [], []\n",
    "                    \n",
    "                    # CVM\n",
    "                    for i in range(20):\n",
    "                        history_x = x_data[-history_length:]\n",
    "                        history_y = y_data[-history_length:]\n",
    "                        assert len(history_x) == history_length\n",
    "                        \n",
    "                        if i == 0:\n",
    "                            vel_x = [history_x[i] - history_x[i-1] for i in range(1, len(history_x))]\n",
    "                            vel_y = [history_y[i] - history_y[i-1] for i in range(1, len(history_y))]\n",
    "                        else:\n",
    "                            vel_x = [(history_x[i] - history_x[i-1]) + np.random.normal(0, 1) for i in range(1, len(history_x))]\n",
    "                            vel_y = [(history_y[i] - history_y[i-1]) + np.random.normal(0, 1) for i in range(1, len(history_y))]\n",
    "                        \n",
    "                        assert len(vel_x) == history_length-1\n",
    "                        avg_vel_x = np.mean(vel_x)\n",
    "                        avg_vel_y = np.mean(vel_y)\n",
    "                        \n",
    "                        pred_x = [x_data[-1] + i*avg_vel_x for i in range(1, 13)]\n",
    "                        pred_y = [y_data[-1] + i*avg_vel_y for i in range(1, 13)]\n",
    "                        assert len(pred_x) == 12\n",
    "                        \n",
    "                        all_pred_x.append(pred_x)\n",
    "                        all_pred_y.append(pred_y)\n",
    "                        \n",
    "\n",
    "                    best_fde = None\n",
    "                    best_ade = None\n",
    "                    for i in range(len(all_pred_x)):\n",
    "                        current_pred_x = all_pred_x[i]\n",
    "                        current_pred_y = all_pred_y[i]\n",
    "\n",
    "                        fde = calculate_FDE(current_pred_x, current_pred_y, x_gt, y_gt)\n",
    "                        if best_fde == None or fde < best_fde:\n",
    "                            best_fde = fde\n",
    "\n",
    "                        ade = calculate_ADE(current_pred_x, current_pred_y, x_gt, y_gt)\n",
    "                        if best_ade == None or ade < best_ade:\n",
    "                            best_ade = ade\n",
    "                        \n",
    "                        # The first prediction (without noise) counts as the result for the single prediction\n",
    "                        if i == 0:\n",
    "                            cvm_fde_single.append(fde)\n",
    "                            cvm_ade_single.append(ade)\n",
    "\n",
    "                    cvm_fde_best_of.append(best_fde)\n",
    "                    cvm_ade_best_of.append(best_ade)\n",
    "                    \n",
    "    return cvm_fde_best_of, cvm_ade_best_of, cvm_fde_single, cvm_ade_single\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a687f69",
   "metadata": {},
   "source": [
    "## Automated results comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef2ab333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_trajectron_data(trajectron_resultset_name, base_folder='./trajectron++/results/', suffix='best_of'):\n",
    "    trajectron_fde = []\n",
    "    with open(base_folder + trajectron_resultset_name + '_fde_' + suffix + '.csv', mode='r') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            trajectron_fde.append(float(row['value']))\n",
    "\n",
    "    trajectron_ade = []\n",
    "    with open(base_folder + trajectron_resultset_name + '_ade_'+ suffix + '.csv', mode='r') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            trajectron_ade.append(float(row['value']))\n",
    "            \n",
    "    return trajectron_fde, trajectron_ade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cf14c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all_datasets(our_method_params, datasets, trajectron_resultset_names, evaluate_most_likely=False):\n",
    "    base_path = './trajectron++/data/'\n",
    "\n",
    "    ours_results = {'BEST_OF_20': {'FDE': [], 'ADE': []}, 'MOST_LIKELY': {'FDE': [], 'ADE': []}}\n",
    "    trajectron_results = {'BEST_OF_20': {'FDE': [], 'ADE': []}, 'MOST_LIKELY': {'FDE': [], 'ADE': []}}\n",
    "    cvm_long_results = {'BEST_OF_20': {'FDE': [], 'ADE': []}, 'MOST_LIKELY': {'FDE': [], 'ADE': []}}\n",
    "    cvm_short_results = {'BEST_OF_20': {'FDE': [], 'ADE': []}, 'MOST_LIKELY': {'FDE': [], 'ADE': []}}\n",
    "\n",
    "    for dataset_idx, dataset in enumerate(datasets):\n",
    "        our_fde_bo20, our_ade_bo20 = [], []\n",
    "        our_fde_most_likely, our_ade_most_likely = [], []\n",
    "        \n",
    "        cvm_fde_bo20, cvm_ade_bo20 = [], []\n",
    "        cvm_short_fde_bo20, cvm_short_ade_bo20 = [], []\n",
    "        \n",
    "        cvm_fde_ml, cvm_ade_ml = [], []\n",
    "        cvm_short_fde_ml, cvm_short_ade_ml = [], []\n",
    "        \n",
    "        for scene_idx, scene in enumerate(dataset):\n",
    "            data = pd.read_csv(base_path + scene, sep='\\t', index_col=False, header=None)\n",
    "            data.columns = ['frame_id', 'track_id', 'pos_x', 'pos_y']\n",
    "\n",
    "            data = process_data(data)\n",
    "\n",
    "            ## Ours\n",
    "            our_fde_best_of_20, our_ade_best_of_20, our_fde_single, our_ade_single = evaluate_our_method(data, our_method_params[dataset_idx], dataset_title=trajectron_resultset_names[dataset_idx], smoothing=False)\n",
    "            our_fde_bo20 += our_fde_best_of_20\n",
    "            our_ade_bo20 += our_ade_best_of_20\n",
    "            if evaluate_most_likely:\n",
    "                our_fde_most_likely += our_fde_single\n",
    "                our_ade_most_likely += our_ade_single\n",
    "\n",
    "            ## CVM\n",
    "            cvm_fde_best_of, cvm_ade_best_of, cvm_fde_single, cvm_ade_single = evaluate_cvm_with_scenarios(data, dataset_title=trajectron_resultset_names[dataset_idx])\n",
    "            cvm_fde_bo20 += cvm_fde_best_of\n",
    "            cvm_ade_bo20 += cvm_ade_best_of\n",
    "            \n",
    "            cvm_fde_short_history_best_of, cvm_ade_short_history_best_of, cvm_fde_short_history_single, cvm_ade_short_history_single = evaluate_cvm_with_scenarios(data, dataset_title=trajectron_resultset_names[dataset_idx], history_length=2)\n",
    "            cvm_short_fde_bo20 += cvm_fde_short_history_best_of\n",
    "            cvm_short_ade_bo20 += cvm_ade_short_history_best_of\n",
    "\n",
    "            if evaluate_most_likely:\n",
    "                cvm_fde_ml += cvm_fde_single\n",
    "                cvm_ade_ml += cvm_ade_single\n",
    "                \n",
    "                cvm_short_fde_ml += cvm_fde_short_history_single\n",
    "                cvm_short_ade_ml += cvm_ade_short_history_single\n",
    "\n",
    "        # add our and CVM results to the data dict\n",
    "        ours_results['BEST_OF_20']['FDE'].append(np.mean(our_fde_bo20))\n",
    "        ours_results['BEST_OF_20']['ADE'].append(np.mean(our_ade_bo20))\n",
    "        if evaluate_most_likely:\n",
    "            ours_results['MOST_LIKELY']['FDE'].append(np.mean(our_fde_most_likely))\n",
    "            ours_results['MOST_LIKELY']['ADE'].append(np.mean(our_ade_most_likely))\n",
    "            \n",
    "        cvm_long_results['BEST_OF_20']['FDE'].append(np.mean(cvm_fde_bo20))\n",
    "        cvm_long_results['BEST_OF_20']['ADE'].append(np.mean(cvm_ade_bo20))\n",
    "        cvm_short_results['BEST_OF_20']['FDE'].append(np.mean(cvm_short_fde_bo20))\n",
    "        cvm_short_results['BEST_OF_20']['ADE'].append(np.mean(cvm_short_ade_bo20))\n",
    "        if evaluate_most_likely:\n",
    "            cvm_long_results['MOST_LIKELY']['FDE'].append(np.mean(cvm_fde_ml))\n",
    "            cvm_long_results['MOST_LIKELY']['ADE'].append(np.mean(cvm_ade_ml))\n",
    "            cvm_short_results['MOST_LIKELY']['FDE'].append(np.mean(cvm_short_fde_ml))\n",
    "            cvm_short_results['MOST_LIKELY']['ADE'].append(np.mean(cvm_short_ade_ml))\n",
    "                \n",
    "        ## Trajectron\n",
    "        trajectron_fde, trajectron_ade = read_trajectron_data(trajectron_resultset_names[dataset_idx])\n",
    "        trajectron_results['BEST_OF_20']['FDE'].append(np.mean(trajectron_fde))\n",
    "        trajectron_results['BEST_OF_20']['ADE'].append(np.mean(trajectron_ade))\n",
    "        \n",
    "        if evaluate_most_likely:\n",
    "            trajectron_fde, trajectron_ade = read_trajectron_data(trajectron_resultset_names[dataset_idx], suffix='most_likely')\n",
    "            trajectron_results['MOST_LIKELY']['FDE'].append(np.mean(trajectron_fde))\n",
    "            trajectron_results['MOST_LIKELY']['ADE'].append(np.mean(trajectron_ade))\n",
    "\n",
    "        # make sure that there is no discrepancy between our data processing and trajectron evaluation results size\n",
    "        if len(dataset) == 1:\n",
    "            num_predictable_trajectories = get_total_predictable_slices(data)\n",
    "            assert len(trajectron_fde) == num_predictable_trajectories\n",
    "            assert len(trajectron_ade) == num_predictable_trajectories\n",
    "    \n",
    "    return [\n",
    "        ours_results,\n",
    "        trajectron_results,\n",
    "        cvm_long_results,\n",
    "        cvm_short_results\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3bcafb",
   "metadata": {},
   "source": [
    "### Parameters of our method for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff64b4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "eth_params = {\n",
    "    'NOISE': 0.05, \n",
    "    'NO_OF_TRAJECTORIES': 500, \n",
    "    'CONST_VEL_MODEL_PROB': 0.5, \n",
    "    'STOP_PROB': 0.025, \n",
    "    'DISCOUNT_AVG_PROB': 1.0, \n",
    "    'DISCOUNT_LOWER_BOUND': 0.15, \n",
    "    'VELOCITY_CHANGE_PROB': 0.1,\n",
    "    'VELOCITY_CHANGE_NOISE': 0.1, \n",
    "    'ANGLE_CHANGE_PROB': 0.2, \n",
    "    'ANGLE_CHANGE_NOISE': 2, \n",
    "    'GROUP_PERCENTAGES': [0.1, 0.5, 0.75, 1.0], \n",
    "    'GROUP_CLUSTER_COUNT': [1, 9, 6, 4]\n",
    "}\n",
    "\n",
    "hotel_params = {\n",
    "    'NOISE': 0.05, \n",
    "    'NO_OF_TRAJECTORIES': 500, \n",
    "    'CONST_VEL_MODEL_PROB': 0.5, \n",
    "    'STOP_PROB': 0.0, \n",
    "    'DISCOUNT_AVG_PROB': 1.0, \n",
    "    'DISCOUNT_LOWER_BOUND': 0.1, \n",
    "    'VELOCITY_CHANGE_PROB': 0.1,\n",
    "    'VELOCITY_CHANGE_NOISE': 0.1, \n",
    "    'ANGLE_CHANGE_PROB': 0.2, \n",
    "    'ANGLE_CHANGE_NOISE': 2, \n",
    "    'GROUP_PERCENTAGES': [0.1, 0.60, 1.0], \n",
    "    'GROUP_CLUSTER_COUNT': [1, 11, 8]\n",
    "}\n",
    "\n",
    "zara1_params = {\n",
    "    'NOISE': 0.05, \n",
    "    'NO_OF_TRAJECTORIES': 500, \n",
    "    'CONST_VEL_MODEL_PROB': 0.5, \n",
    "    'STOP_PROB': 0.0, \n",
    "    'DISCOUNT_AVG_PROB': 1.0, \n",
    "    'DISCOUNT_LOWER_BOUND': 0.2, \n",
    "    'VELOCITY_CHANGE_PROB': 0.1,\n",
    "    'VELOCITY_CHANGE_NOISE': 0.1, \n",
    "    'ANGLE_CHANGE_PROB': 0.2, \n",
    "    'ANGLE_CHANGE_NOISE': 2, \n",
    "    'GROUP_PERCENTAGES': [0.1, 0.60, 1.0], \n",
    "    'GROUP_CLUSTER_COUNT': [1, 14, 5]\n",
    "}\n",
    "\n",
    "zara2_params = {\n",
    "    'NOISE': 0.1, \n",
    "    'NO_OF_TRAJECTORIES': 500, \n",
    "    'CONST_VEL_MODEL_PROB': 0.5, \n",
    "    'STOP_PROB': 0.025, \n",
    "    'DISCOUNT_AVG_PROB': 1.0, \n",
    "    'DISCOUNT_LOWER_BOUND': 0.2, \n",
    "    'VELOCITY_CHANGE_PROB': 0.1,\n",
    "    'VELOCITY_CHANGE_NOISE': 0.1, \n",
    "    'ANGLE_CHANGE_PROB': 0.1, \n",
    "    'ANGLE_CHANGE_NOISE': 2, \n",
    "    'GROUP_PERCENTAGES': [0.1, 0.60, 1.0], \n",
    "    'GROUP_CLUSTER_COUNT': [1, 14, 5]\n",
    "}\n",
    "\n",
    "univ_params = {\n",
    "    'NOISE': 0.025, \n",
    "    'NO_OF_TRAJECTORIES': 500, \n",
    "    'CONST_VEL_MODEL_PROB': 0.5, \n",
    "    'STOP_PROB': 0.05, \n",
    "    'DISCOUNT_AVG_PROB': 1.0, \n",
    "    'DISCOUNT_LOWER_BOUND': 0.1, \n",
    "    'VELOCITY_CHANGE_PROB': 0.1,\n",
    "    'VELOCITY_CHANGE_NOISE': 0.1, \n",
    "    'ANGLE_CHANGE_PROB': 0.2, \n",
    "    'ANGLE_CHANGE_NOISE': 2, \n",
    "    'GROUP_PERCENTAGES': [0.1, 0.5, 0.75, 1.0], \n",
    "    'GROUP_CLUSTER_COUNT': [1, 9, 6, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eac9d82",
   "metadata": {},
   "source": [
    "### Running the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a429d4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ours - eth_vel: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 484/484 [00:32<00:00, 14.92it/s]\n",
      "CVM - eth_vel: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 484/484 [00:01<00:00, 481.86it/s]\n",
      "CVM - eth_vel: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 484/484 [00:00<00:00, 556.59it/s]\n",
      "Ours - hotel_vel: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 913/913 [01:47<00:00,  8.50it/s]\n",
      "CVM - hotel_vel: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 913/913 [00:03<00:00, 245.68it/s]\n",
      "CVM - hotel_vel: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 913/913 [00:03<00:00, 275.22it/s]\n",
      "Ours - univ_vel:  28%|█████████████████████████▍                                                                 | 124/444 [05:53<15:42,  2.95s/it]"
     ]
    }
   ],
   "source": [
    "our_method_params = [eth_params, hotel_params, univ_params, zara1_params, zara2_params]\n",
    "\n",
    "datasets = [\n",
    "    ['biwi_eth.txt'], \n",
    "    ['biwi_hotel.txt'], \n",
    "    ['students001.txt', 'students003.txt'],\n",
    "    ['crowds_zara01.txt'], \n",
    "    ['crowds_zara02.txt'],\n",
    "]\n",
    "\n",
    "trajectron_resultset_names = [\n",
    "    'eth_vel', \n",
    "    'hotel_vel',\n",
    "    'univ_vel',\n",
    "    'zara1_vel', \n",
    "    'zara2_vel',\n",
    "]\n",
    "\n",
    "res = evaluate_all_datasets(our_method_params, datasets, trajectron_resultset_names, evaluate_most_likely=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7260ac78",
   "metadata": {},
   "outputs": [],
   "source": [
    "ours_results = res[0]\n",
    "trajectron_results = res[1]\n",
    "cvm_long_results = res[2]\n",
    "cvm_short_results = res[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab25de20",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [\n",
    "    'ETH', \n",
    "    'Hotel', \n",
    "    'Univ',\n",
    "    'Zara 1', \n",
    "    'Zara 2',\n",
    "]\n",
    "\n",
    "df_data_best_of_20_fde = {\n",
    "    'CVM (8pt history)' : pd.Series(cvm_long_results['BEST_OF_20']['FDE'], index = index),\n",
    "    'CVM (2pt history)' : pd.Series(cvm_short_results['BEST_OF_20']['FDE'], index = index),\n",
    "    'Trajectron++' : pd.Series(trajectron_results['BEST_OF_20']['FDE'], index = index),\n",
    "    'Ours': pd.Series(ours_results['BEST_OF_20']['FDE'], index = index)\n",
    "}\n",
    "\n",
    "df_best_of_20_fde = pd.DataFrame(df_data_best_of_20_fde)\n",
    "df_best_of_20_fde.loc['Average'] = df_best_of_20_fde.mean()\n",
    "\n",
    "df_data_best_of_20_ade = {\n",
    "    'CVM (8pt history)' : pd.Series(cvm_long_results['BEST_OF_20']['ADE'], index = index),\n",
    "    'CVM (2pt history)' : pd.Series(cvm_short_results['BEST_OF_20']['ADE'], index = index),\n",
    "    'Trajectron++' : pd.Series(trajectron_results['BEST_OF_20']['ADE'], index = index),\n",
    "    'Ours': pd.Series(ours_results['BEST_OF_20']['ADE'], index = index)\n",
    "}\n",
    "\n",
    "df_best_of_20_ade = pd.DataFrame(df_data_best_of_20_ade)\n",
    "df_best_of_20_ade.loc['Average'] = df_best_of_20_ade.mean()\n",
    "\n",
    "df_data_most_likely_fde = {\n",
    "    'CVM (8pt history)' : pd.Series(cvm_long_results['MOST_LIKELY']['FDE'], index = index),\n",
    "    'CVM (2pt history)' : pd.Series(cvm_short_results['MOST_LIKELY']['FDE'], index = index),\n",
    "    'Trajectron++' : pd.Series(trajectron_results['MOST_LIKELY']['FDE'], index = index),\n",
    "    'Ours': pd.Series(ours_results['MOST_LIKELY']['FDE'], index = index)\n",
    "}\n",
    "\n",
    "df_most_likely_fde = pd.DataFrame(df_data_most_likely_fde)\n",
    "df_most_likely_fde.loc['Average'] = df_most_likely_fde.mean()\n",
    "\n",
    "df_data_most_likely_ade = {\n",
    "    'CVM (8pt history)' : pd.Series(cvm_long_results['MOST_LIKELY']['ADE'], index = index),\n",
    "    'CVM (2pt history)' : pd.Series(cvm_short_results['MOST_LIKELY']['ADE'], index = index),\n",
    "    'Trajectron++' : pd.Series(trajectron_results['MOST_LIKELY']['ADE'], index = index),\n",
    "    'Ours': pd.Series(ours_results['MOST_LIKELY']['ADE'], index = index)\n",
    "}\n",
    "\n",
    "df_most_likely_ade = pd.DataFrame(df_data_most_likely_ade)\n",
    "df_most_likely_ade.loc['Average'] = df_most_likely_ade.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc41968",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f64a9ed",
   "metadata": {},
   "source": [
    "### Best of 20 - FDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f50969a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b352f_row0_col3, #T_b352f_row1_col3, #T_b352f_row2_col3, #T_b352f_row3_col2, #T_b352f_row4_col2, #T_b352f_row5_col3 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b352f_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >CVM (8pt history)</th>\n",
       "      <th class=\"col_heading level0 col1\" >CVM (2pt history)</th>\n",
       "      <th class=\"col_heading level0 col2\" >Trajectron++</th>\n",
       "      <th class=\"col_heading level0 col3\" >Ours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b352f_level0_row0\" class=\"row_heading level0 row0\" >ETH</th>\n",
       "      <td id=\"T_b352f_row0_col0\" class=\"data row0 col0\" >1.134</td>\n",
       "      <td id=\"T_b352f_row0_col1\" class=\"data row0 col1\" >1.726</td>\n",
       "      <td id=\"T_b352f_row0_col2\" class=\"data row0 col2\" >0.812</td>\n",
       "      <td id=\"T_b352f_row0_col3\" class=\"data row0 col3\" >0.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b352f_level0_row1\" class=\"row_heading level0 row1\" >Hotel</th>\n",
       "      <td id=\"T_b352f_row1_col0\" class=\"data row1 col0\" >0.374</td>\n",
       "      <td id=\"T_b352f_row1_col1\" class=\"data row1 col1\" >0.580</td>\n",
       "      <td id=\"T_b352f_row1_col2\" class=\"data row1 col2\" >0.197</td>\n",
       "      <td id=\"T_b352f_row1_col3\" class=\"data row1 col3\" >0.183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b352f_level0_row2\" class=\"row_heading level0 row2\" >Univ</th>\n",
       "      <td id=\"T_b352f_row2_col0\" class=\"data row2 col0\" >0.885</td>\n",
       "      <td id=\"T_b352f_row2_col1\" class=\"data row2 col1\" >1.057</td>\n",
       "      <td id=\"T_b352f_row2_col2\" class=\"data row2 col2\" >0.450</td>\n",
       "      <td id=\"T_b352f_row2_col3\" class=\"data row2 col3\" >0.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b352f_level0_row3\" class=\"row_heading level0 row3\" >Zara 1</th>\n",
       "      <td id=\"T_b352f_row3_col0\" class=\"data row3 col0\" >0.792</td>\n",
       "      <td id=\"T_b352f_row3_col1\" class=\"data row3 col1\" >0.883</td>\n",
       "      <td id=\"T_b352f_row3_col2\" class=\"data row3 col2\" >0.342</td>\n",
       "      <td id=\"T_b352f_row3_col3\" class=\"data row3 col3\" >0.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b352f_level0_row4\" class=\"row_heading level0 row4\" >Zara 2</th>\n",
       "      <td id=\"T_b352f_row4_col0\" class=\"data row4 col0\" >0.552</td>\n",
       "      <td id=\"T_b352f_row4_col1\" class=\"data row4 col1\" >0.651</td>\n",
       "      <td id=\"T_b352f_row4_col2\" class=\"data row4 col2\" >0.253</td>\n",
       "      <td id=\"T_b352f_row4_col3\" class=\"data row4 col3\" >0.308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b352f_level0_row5\" class=\"row_heading level0 row5\" >Average</th>\n",
       "      <td id=\"T_b352f_row5_col0\" class=\"data row5 col0\" >0.747</td>\n",
       "      <td id=\"T_b352f_row5_col1\" class=\"data row5 col1\" >0.979</td>\n",
       "      <td id=\"T_b352f_row5_col2\" class=\"data row5 col2\" >0.411</td>\n",
       "      <td id=\"T_b352f_row5_col3\" class=\"data row5 col3\" >0.402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x157377250>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_best_of_20_fde.style.highlight_min(color = 'lightgreen', axis = 1).format(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2296114d",
   "metadata": {},
   "source": [
    "### Best of 20 - ADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25a02de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_471a3_row0_col2, #T_471a3_row1_col2, #T_471a3_row2_col2, #T_471a3_row3_col2, #T_471a3_row4_col2, #T_471a3_row5_col2 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_471a3_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >CVM (8pt history)</th>\n",
       "      <th class=\"col_heading level0 col1\" >CVM (2pt history)</th>\n",
       "      <th class=\"col_heading level0 col2\" >Trajectron++</th>\n",
       "      <th class=\"col_heading level0 col3\" >Ours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_471a3_level0_row0\" class=\"row_heading level0 row0\" >ETH</th>\n",
       "      <td id=\"T_471a3_row0_col0\" class=\"data row0 col0\" >0.647</td>\n",
       "      <td id=\"T_471a3_row0_col1\" class=\"data row0 col1\" >0.892</td>\n",
       "      <td id=\"T_471a3_row0_col2\" class=\"data row0 col2\" >0.396</td>\n",
       "      <td id=\"T_471a3_row0_col3\" class=\"data row0 col3\" >0.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_471a3_level0_row1\" class=\"row_heading level0 row1\" >Hotel</th>\n",
       "      <td id=\"T_471a3_row1_col0\" class=\"data row1 col0\" >0.209</td>\n",
       "      <td id=\"T_471a3_row1_col1\" class=\"data row1 col1\" >0.306</td>\n",
       "      <td id=\"T_471a3_row1_col2\" class=\"data row1 col2\" >0.115</td>\n",
       "      <td id=\"T_471a3_row1_col3\" class=\"data row1 col3\" >0.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_471a3_level0_row2\" class=\"row_heading level0 row2\" >Univ</th>\n",
       "      <td id=\"T_471a3_row2_col0\" class=\"data row2 col0\" >0.474</td>\n",
       "      <td id=\"T_471a3_row2_col1\" class=\"data row2 col1\" >0.491</td>\n",
       "      <td id=\"T_471a3_row2_col2\" class=\"data row2 col2\" >0.205</td>\n",
       "      <td id=\"T_471a3_row2_col3\" class=\"data row2 col3\" >0.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_471a3_level0_row3\" class=\"row_heading level0 row3\" >Zara 1</th>\n",
       "      <td id=\"T_471a3_row3_col0\" class=\"data row3 col0\" >0.416</td>\n",
       "      <td id=\"T_471a3_row3_col1\" class=\"data row3 col1\" >0.408</td>\n",
       "      <td id=\"T_471a3_row3_col2\" class=\"data row3 col2\" >0.155</td>\n",
       "      <td id=\"T_471a3_row3_col3\" class=\"data row3 col3\" >0.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_471a3_level0_row4\" class=\"row_heading level0 row4\" >Zara 2</th>\n",
       "      <td id=\"T_471a3_row4_col0\" class=\"data row4 col0\" >0.295</td>\n",
       "      <td id=\"T_471a3_row4_col1\" class=\"data row4 col1\" >0.302</td>\n",
       "      <td id=\"T_471a3_row4_col2\" class=\"data row4 col2\" >0.115</td>\n",
       "      <td id=\"T_471a3_row4_col3\" class=\"data row4 col3\" >0.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_471a3_level0_row5\" class=\"row_heading level0 row5\" >Average</th>\n",
       "      <td id=\"T_471a3_row5_col0\" class=\"data row5 col0\" >0.408</td>\n",
       "      <td id=\"T_471a3_row5_col1\" class=\"data row5 col1\" >0.480</td>\n",
       "      <td id=\"T_471a3_row5_col2\" class=\"data row5 col2\" >0.197</td>\n",
       "      <td id=\"T_471a3_row5_col3\" class=\"data row5 col3\" >0.260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1180791f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_best_of_20_ade.style.highlight_min(color = 'lightgreen', axis = 1).format(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cee6f79",
   "metadata": {},
   "source": [
    "### Single output - FDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c3796e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d4e70_row0_col2, #T_d4e70_row1_col3, #T_d4e70_row2_col1, #T_d4e70_row3_col2, #T_d4e70_row4_col2, #T_d4e70_row5_col2 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d4e70_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >CVM (8pt history)</th>\n",
       "      <th class=\"col_heading level0 col1\" >CVM (2pt history)</th>\n",
       "      <th class=\"col_heading level0 col2\" >Trajectron++</th>\n",
       "      <th class=\"col_heading level0 col3\" >Ours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d4e70_level0_row0\" class=\"row_heading level0 row0\" >ETH</th>\n",
       "      <td id=\"T_d4e70_row0_col0\" class=\"data row0 col0\" >2.303</td>\n",
       "      <td id=\"T_d4e70_row0_col1\" class=\"data row0 col1\" >2.282</td>\n",
       "      <td id=\"T_d4e70_row0_col2\" class=\"data row0 col2\" >1.615</td>\n",
       "      <td id=\"T_d4e70_row0_col3\" class=\"data row0 col3\" >2.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4e70_level0_row1\" class=\"row_heading level0 row1\" >Hotel</th>\n",
       "      <td id=\"T_d4e70_row1_col0\" class=\"data row1 col0\" >0.462</td>\n",
       "      <td id=\"T_d4e70_row1_col1\" class=\"data row1 col1\" >0.614</td>\n",
       "      <td id=\"T_d4e70_row1_col2\" class=\"data row1 col2\" >0.499</td>\n",
       "      <td id=\"T_d4e70_row1_col3\" class=\"data row1 col3\" >0.402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4e70_level0_row2\" class=\"row_heading level0 row2\" >Univ</th>\n",
       "      <td id=\"T_d4e70_row2_col0\" class=\"data row2 col0\" >1.370</td>\n",
       "      <td id=\"T_d4e70_row2_col1\" class=\"data row2 col1\" >1.165</td>\n",
       "      <td id=\"T_d4e70_row2_col2\" class=\"data row2 col2\" >1.205</td>\n",
       "      <td id=\"T_d4e70_row2_col3\" class=\"data row2 col3\" >1.198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4e70_level0_row3\" class=\"row_heading level0 row3\" >Zara 1</th>\n",
       "      <td id=\"T_d4e70_row3_col0\" class=\"data row3 col0\" >1.132</td>\n",
       "      <td id=\"T_d4e70_row3_col1\" class=\"data row3 col1\" >0.952</td>\n",
       "      <td id=\"T_d4e70_row3_col2\" class=\"data row3 col2\" >0.770</td>\n",
       "      <td id=\"T_d4e70_row3_col3\" class=\"data row3 col3\" >1.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4e70_level0_row4\" class=\"row_heading level0 row4\" >Zara 2</th>\n",
       "      <td id=\"T_d4e70_row4_col0\" class=\"data row4 col0\" >0.860</td>\n",
       "      <td id=\"T_d4e70_row4_col1\" class=\"data row4 col1\" >0.724</td>\n",
       "      <td id=\"T_d4e70_row4_col2\" class=\"data row4 col2\" >0.589</td>\n",
       "      <td id=\"T_d4e70_row4_col3\" class=\"data row4 col3\" >0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d4e70_level0_row5\" class=\"row_heading level0 row5\" >Average</th>\n",
       "      <td id=\"T_d4e70_row5_col0\" class=\"data row5 col0\" >1.226</td>\n",
       "      <td id=\"T_d4e70_row5_col1\" class=\"data row5 col1\" >1.148</td>\n",
       "      <td id=\"T_d4e70_row5_col2\" class=\"data row5 col2\" >0.936</td>\n",
       "      <td id=\"T_d4e70_row5_col3\" class=\"data row5 col3\" >1.087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x118079c70>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_most_likely_fde.style.highlight_min(color = 'lightgreen', axis = 1).format(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e3ac08",
   "metadata": {},
   "source": [
    "### Single output - ADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ff1e486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_57f26_row0_col2, #T_57f26_row1_col3, #T_57f26_row2_col2, #T_57f26_row3_col2, #T_57f26_row4_col2, #T_57f26_row5_col2 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_57f26_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >CVM (8pt history)</th>\n",
       "      <th class=\"col_heading level0 col1\" >CVM (2pt history)</th>\n",
       "      <th class=\"col_heading level0 col2\" >Trajectron++</th>\n",
       "      <th class=\"col_heading level0 col3\" >Ours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_57f26_level0_row0\" class=\"row_heading level0 row0\" >ETH</th>\n",
       "      <td id=\"T_57f26_row0_col0\" class=\"data row0 col0\" >1.102</td>\n",
       "      <td id=\"T_57f26_row0_col1\" class=\"data row0 col1\" >1.075</td>\n",
       "      <td id=\"T_57f26_row0_col2\" class=\"data row0 col2\" >0.695</td>\n",
       "      <td id=\"T_57f26_row0_col3\" class=\"data row0 col3\" >0.961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_57f26_level0_row1\" class=\"row_heading level0 row1\" >Hotel</th>\n",
       "      <td id=\"T_57f26_row1_col0\" class=\"data row1 col0\" >0.243</td>\n",
       "      <td id=\"T_57f26_row1_col1\" class=\"data row1 col1\" >0.319</td>\n",
       "      <td id=\"T_57f26_row1_col2\" class=\"data row1 col2\" >0.224</td>\n",
       "      <td id=\"T_57f26_row1_col3\" class=\"data row1 col3\" >0.213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_57f26_level0_row2\" class=\"row_heading level0 row2\" >Univ</th>\n",
       "      <td id=\"T_57f26_row2_col0\" class=\"data row2 col0\" >0.676</td>\n",
       "      <td id=\"T_57f26_row2_col1\" class=\"data row2 col1\" >0.524</td>\n",
       "      <td id=\"T_57f26_row2_col2\" class=\"data row2 col2\" >0.468</td>\n",
       "      <td id=\"T_57f26_row2_col3\" class=\"data row2 col3\" >0.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_57f26_level0_row3\" class=\"row_heading level0 row3\" >Zara 1</th>\n",
       "      <td id=\"T_57f26_row3_col0\" class=\"data row3 col0\" >0.552</td>\n",
       "      <td id=\"T_57f26_row3_col1\" class=\"data row3 col1\" >0.427</td>\n",
       "      <td id=\"T_57f26_row3_col2\" class=\"data row3 col2\" >0.297</td>\n",
       "      <td id=\"T_57f26_row3_col3\" class=\"data row3 col3\" >0.480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_57f26_level0_row4\" class=\"row_heading level0 row4\" >Zara 2</th>\n",
       "      <td id=\"T_57f26_row4_col0\" class=\"data row4 col0\" >0.421</td>\n",
       "      <td id=\"T_57f26_row4_col1\" class=\"data row4 col1\" >0.324</td>\n",
       "      <td id=\"T_57f26_row4_col2\" class=\"data row4 col2\" >0.227</td>\n",
       "      <td id=\"T_57f26_row4_col3\" class=\"data row4 col3\" >0.381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_57f26_level0_row5\" class=\"row_heading level0 row5\" >Average</th>\n",
       "      <td id=\"T_57f26_row5_col0\" class=\"data row5 col0\" >0.599</td>\n",
       "      <td id=\"T_57f26_row5_col1\" class=\"data row5 col1\" >0.534</td>\n",
       "      <td id=\"T_57f26_row5_col2\" class=\"data row5 col2\" >0.382</td>\n",
       "      <td id=\"T_57f26_row5_col3\" class=\"data row5 col3\" >0.521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x157356640>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_most_likely_ade.style.highlight_min(color = 'lightgreen', axis = 1).format(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7330eb4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
