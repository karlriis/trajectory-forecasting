{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d1740c3",
   "metadata": {},
   "source": [
    "# Results comparison between Trajectron++ and our method\n",
    "Comparing the results of our method with the Trajectron++ paper's method. The goal of the comparison is to evaluate Trajectron++ on a different dataset than it was trained on to allow more fair comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfa130bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import generative_model\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dd1a8c",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ac04490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_FDE(pred_x, pred_y, test_x, test_y):\n",
    "\n",
    "    final_displacement_x = pred_x[-1] - test_x[-1]\n",
    "    final_displacement_y = pred_y[-1] - test_y[-1]\n",
    "    FDE = np.sqrt(final_displacement_x**2 + final_displacement_y**2)\n",
    "    \n",
    "    return FDE\n",
    "\n",
    "def calculate_ADE(pred_x, pred_y, test_x, test_y):\n",
    "    assert len(pred_x) == len(test_x)\n",
    "    total_displacement_error = 0\n",
    "    for point_idx in range(len(test_x)):\n",
    "        displacement_error = np.sqrt((pred_x[point_idx] - test_x[point_idx])**2 + (pred_y[point_idx] - test_y[point_idx])**2)\n",
    "        total_displacement_error += displacement_error\n",
    "\n",
    "    return total_displacement_error/len(pred_x)\n",
    "\n",
    "## The evaluation logic for Trajectron++ loops over the frames and predicts the future trajectories \n",
    "## for each node present in the current frame\n",
    "## Each node has to have at least 7 historical points and 12 future points\n",
    "def get_total_predictable_slices(data):\n",
    "    total_predictable_steps = 0\n",
    "    for i in pd.unique(data.node_id):\n",
    "        #print(len(test[test.node_id == i]))\n",
    "        total_predictable_steps += len(data[data.node_id == i]) - 19\n",
    "    return total_predictable_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "907d43d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(input_data):\n",
    "    data = input_data.copy()\n",
    "    data['frame_id'] = pd.to_numeric(data['frame_id'], downcast='integer')\n",
    "    data['track_id'] = pd.to_numeric(data['track_id'], downcast='integer')\n",
    "\n",
    "    data['frame_id'] = data['frame_id'] // 10\n",
    "\n",
    "    data['frame_id'] -= data['frame_id'].min()\n",
    "\n",
    "    data['node_type'] = 'PEDESTRIAN'\n",
    "    data['node_id'] = data['track_id'].astype(str)\n",
    "    data.sort_values('frame_id', inplace=True)\n",
    "\n",
    "    data['pos_x'] = data['pos_x'] - data['pos_x'].mean()\n",
    "    data['pos_y'] = data['pos_y'] - data['pos_y'].mean()\n",
    "    \n",
    "    # Select only such nodes which have enough data to predict on (8 historical timesteps, 12 future)\n",
    "    v = data.node_id.value_counts()\n",
    "    data = data[data.node_id.isin(v.index[v.gt(19)])]\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce140413",
   "metadata": {},
   "source": [
    "## Method evaluation logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46e27d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_our_method(data, params, dataset_title='', clustering_method='KMeans', smoothing=False):\n",
    "    our_fde_best_of = []\n",
    "    our_ade_best_of = []\n",
    "    our_fde_single = []\n",
    "    our_ade_single = []\n",
    "\n",
    "    # Loop over the dataset frame by frame\n",
    "    for frame_id in tqdm(pd.unique(data.frame_id), desc='Ours - ' + dataset_title):\n",
    "\n",
    "        frame_data = data[data.frame_id == frame_id]\n",
    "        \n",
    "        # Loop over all agents in the current frame\n",
    "        for node_id in pd.unique(frame_data.node_id):\n",
    "            # Check for 8 points of history for current agent\n",
    "            if len(data[((data.node_id == node_id) & (data.frame_id <= frame_id))]) >= 8:\n",
    "                # Check for 12 points of future for current agent\n",
    "                if len(data[((data.node_id == node_id) & (data.frame_id > frame_id))]) >= 12:\n",
    "                    node_history_data = data[((data.node_id == node_id) & (data.frame_id <= frame_id) & (data.frame_id >= frame_id-7))]\n",
    "                    node_gt_data = data[((data.node_id == node_id) & (data.frame_id > frame_id) & (data.frame_id <= frame_id+12))]\n",
    "\n",
    "                    x_data = list(node_history_data.pos_x)\n",
    "                    y_data = list(node_history_data.pos_y)\n",
    "                    assert len(x_data) == 8\n",
    "\n",
    "                    x_gt = list(node_gt_data.pos_x)\n",
    "                    y_gt = list(node_gt_data.pos_y)\n",
    "                    assert len(x_gt) == 12\n",
    "\n",
    "                    all_pred_x, all_pred_y, weights = generative_model.predict(x_data, y_data, params, trajectory_length=12, clustering_method=clustering_method, smoothing=smoothing)\n",
    "                    assert len(all_pred_x[0]) == 12\n",
    "                    \n",
    "                    # This section is for producing a single trajectory\n",
    "                    # Choose the first prediction (i.e. the most likely one)\n",
    "                    single_x = all_pred_x[0]\n",
    "                    single_y = all_pred_y[0]\n",
    "                    \n",
    "                    # Choose the weighted average\n",
    "                    #single_x = np.average(all_pred_x, axis=0, weights=weights)\n",
    "                    #single_y = np.average(all_pred_y, axis=0, weights=weights)\n",
    "                    \n",
    "                    # Choose the mean\n",
    "                    #single_x = np.mean(all_pred_x, axis=0)\n",
    "                    #single_y = np.mean(all_pred_y, axis=0)\n",
    "                    single_fde = calculate_FDE(single_x, single_y, x_gt, y_gt)\n",
    "                    single_ade = calculate_ADE(single_x, single_y, x_gt, y_gt)\n",
    "                    our_fde_single.append(single_fde)\n",
    "                    our_ade_single.append(single_ade)\n",
    "                        \n",
    "                        \n",
    "                    # This section is for finding the best trajectories out of many in terms of FDE and ADE\n",
    "                    best_fde = None\n",
    "                    best_ade = None\n",
    "\n",
    "                    for i in range(len(all_pred_x)):\n",
    "                        current_pred_x = all_pred_x[i]\n",
    "                        current_pred_y = all_pred_y[i]\n",
    "\n",
    "                        fde = calculate_FDE(current_pred_x, current_pred_y, x_gt, y_gt)\n",
    "                        if best_fde == None or fde < best_fde:\n",
    "                            best_fde = fde\n",
    "\n",
    "                        ade = calculate_ADE(current_pred_x, current_pred_y, x_gt, y_gt)\n",
    "                        if best_ade == None or ade < best_ade:\n",
    "                            best_ade = ade\n",
    "\n",
    "                    our_fde_best_of.append(best_fde)\n",
    "                    our_ade_best_of.append(best_ade)\n",
    "                    \n",
    "    return our_fde_best_of, our_ade_best_of, our_fde_single, our_ade_single\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "781a48eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cvm_with_scenarios(data, dataset_title='', history_length=8):\n",
    "    tot = 0\n",
    "    our_fde_best_of = []\n",
    "    our_ade_best_of = []\n",
    "\n",
    "    for frame_id in tqdm(pd.unique(data.frame_id), desc='CVM - ' + dataset_title):\n",
    "\n",
    "        frame_data = data[data.frame_id == frame_id]\n",
    "        #print(frame_data)\n",
    "        for node_id in pd.unique(frame_data.node_id):\n",
    "            # Check if at least 7 historical points are present\n",
    "            # PS: It might be so that the prediction starts at the 8th step instead of 7th? Edited the code to do this at the moment\n",
    "            if len(data[((data.node_id == node_id) & (data.frame_id <= frame_id))]) >= 8:\n",
    "                # Not sure why there has to be more than 12 frames to the future (at least 13) but it's the\n",
    "                # only way to get the number of trajectron++ eval predictions to match up\n",
    "                if len(data[((data.node_id == node_id) & (data.frame_id > frame_id))]) >= 12:\n",
    "                    tot += 1\n",
    "                    node_history_data = data[((data.node_id == node_id) & (data.frame_id <= frame_id) & (data.frame_id >= frame_id-7))]\n",
    "                    node_gt_data = data[((data.node_id == node_id) & (data.frame_id > frame_id) & (data.frame_id <= frame_id+12))]\n",
    "\n",
    "                    x_data = list(node_history_data.pos_x)\n",
    "                    y_data = list(node_history_data.pos_y)\n",
    "                    assert len(x_data) == 8\n",
    "\n",
    "                    x_gt = list(node_gt_data.pos_x)\n",
    "                    y_gt = list(node_gt_data.pos_y)\n",
    "                    assert len(x_gt) == 12\n",
    "\n",
    "                    all_pred_x, all_pred_y = [], []\n",
    "                    \n",
    "                    # CVM\n",
    "                    for i in range(20):\n",
    "                        history_x = x_data[-history_length:]\n",
    "                        history_y = y_data[-history_length:]\n",
    "                        assert len(history_x) == history_length\n",
    "                        \n",
    "                        if i == 0:\n",
    "                            vel_x = [history_x[i] - history_x[i-1] for i in range(1, len(history_x))]\n",
    "                            vel_y = [history_y[i] - history_y[i-1] for i in range(1, len(history_y))]\n",
    "                        else:\n",
    "                            vel_x = [(history_x[i] - history_x[i-1]) + np.random.normal(0, 1) for i in range(1, len(history_x))]\n",
    "                            vel_y = [(history_y[i] - history_y[i-1]) + np.random.normal(0, 1) for i in range(1, len(history_y))]\n",
    "                        \n",
    "                        assert len(vel_x) == history_length-1\n",
    "                        avg_vel_x = np.mean(vel_x)\n",
    "                        avg_vel_y = np.mean(vel_y)\n",
    "                        \n",
    "                        pred_x = [x_data[-1] + i*avg_vel_x for i in range(1, 13)]\n",
    "                        pred_y = [y_data[-1] + i*avg_vel_y for i in range(1, 13)]\n",
    "                        assert len(pred_x) == 12\n",
    "                        \n",
    "                        all_pred_x.append(pred_x)\n",
    "                        all_pred_y.append(pred_y)\n",
    "                    \n",
    "\n",
    "                    best_fde = None\n",
    "                    best_ade = None\n",
    "                    for i in range(len(all_pred_x)):\n",
    "                        current_pred_x = all_pred_x[i]\n",
    "                        current_pred_y = all_pred_y[i]\n",
    "\n",
    "                        fde = calculate_FDE(current_pred_x, current_pred_y, x_gt, y_gt)\n",
    "                        if best_fde == None or fde < best_fde:\n",
    "                            best_fde = fde\n",
    "\n",
    "                        ade = calculate_ADE(current_pred_x, current_pred_y, x_gt, y_gt)\n",
    "                        if best_ade == None or ade < best_ade:\n",
    "                            best_ade = ade\n",
    "\n",
    "                    our_fde_best_of.append(best_fde)\n",
    "                    our_ade_best_of.append(best_ade)\n",
    "                    \n",
    "    return our_fde_best_of, our_ade_best_of\n",
    "\n",
    "def evaluate_cvm(data, dataset_title='', history_length=8):\n",
    "    tot = 0\n",
    "    all_fde = []\n",
    "    all_ade = []\n",
    "\n",
    "    for frame_id in tqdm(pd.unique(data.frame_id), desc='CVM - ' + dataset_title):\n",
    "\n",
    "        frame_data = data[data.frame_id == frame_id]\n",
    "        #print(frame_data)\n",
    "        for node_id in pd.unique(frame_data.node_id):\n",
    "            # Check if at least 7 historical points are present\n",
    "            # PS: It might be so that the prediction starts at the 8th step instead of 7th? Edited the code to do this at the moment\n",
    "            if len(data[((data.node_id == node_id) & (data.frame_id <= frame_id))]) >= 8:\n",
    "                # Not sure why there has to be more than 12 frames to the future (at least 13) but it's the\n",
    "                # only way to get the number of trajectron++ eval predictions to match up\n",
    "                if len(data[((data.node_id == node_id) & (data.frame_id > frame_id))]) >= 12:\n",
    "                    tot += 1\n",
    "                    node_history_data = data[((data.node_id == node_id) & (data.frame_id <= frame_id) & (data.frame_id >= frame_id-7))]\n",
    "                    node_gt_data = data[((data.node_id == node_id) & (data.frame_id > frame_id) & (data.frame_id <= frame_id+12))]\n",
    "\n",
    "                    x_data = list(node_history_data.pos_x)\n",
    "                    y_data = list(node_history_data.pos_y)\n",
    "                    assert len(x_data) == 8\n",
    "\n",
    "                    x_gt = list(node_gt_data.pos_x)\n",
    "                    y_gt = list(node_gt_data.pos_y)\n",
    "                    assert len(x_gt) == 12\n",
    "\n",
    "                    history_x = x_data[-history_length:]\n",
    "                    history_y = y_data[-history_length:]\n",
    "                    assert len(history_x) == history_length\n",
    "\n",
    "                    vel_x = [history_x[i] - history_x[i-1] for i in range(1, len(history_x))]\n",
    "                    vel_y = [history_y[i] - history_y[i-1] for i in range(1, len(history_y))]\n",
    "\n",
    "                    assert len(vel_x) == history_length-1\n",
    "                    avg_vel_x = np.mean(vel_x)\n",
    "                    avg_vel_y = np.mean(vel_y)\n",
    "\n",
    "                    pred_x = [x_data[-1] + i*avg_vel_x for i in range(1, 13)]\n",
    "                    pred_y = [y_data[-1] + i*avg_vel_y for i in range(1, 13)]\n",
    "                    assert len(pred_x) == 12\n",
    "\n",
    "                    fde = calculate_FDE(pred_x, pred_y, x_gt, y_gt)\n",
    "                    ade = calculate_ADE(pred_x, pred_y, x_gt, y_gt)\n",
    "\n",
    "                    all_fde.append(fde)\n",
    "                    all_ade.append(ade)\n",
    "                    \n",
    "    return all_fde, all_ade\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a687f69",
   "metadata": {},
   "source": [
    "## Automated results comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef2ab333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_trajectron_data(trajectron_resultset_name, base_folder='./trajectron++/results_paper_version/', suffix='best_of'):\n",
    "    trajectron_fde = []\n",
    "    with open(base_folder + trajectron_resultset_name + '_fde_' + suffix + '.csv', mode='r') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            trajectron_fde.append(float(row['value']))\n",
    "\n",
    "    trajectron_ade = []\n",
    "    with open(base_folder + trajectron_resultset_name + '_ade_'+ suffix + '.csv', mode='r') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            trajectron_ade.append(float(row['value']))\n",
    "            \n",
    "    return trajectron_fde, trajectron_ade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cf14c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all_datasets(our_method_params, datasets, trajectron_resultset_names, trajectron_ar3_resultset_names, evaluate_most_likely=False, evaluate_with_interactions=False):\n",
    "    base_path = './raw_data/'\n",
    "\n",
    "    ours_results = {'BEST_OF_20': {'FDE': [], 'ADE': []}, 'MOST_LIKELY': {'FDE': [], 'ADE': []}}\n",
    "    trajectron_results = {'BEST_OF_20': {'FDE': [], 'ADE': []}, 'MOST_LIKELY': {'FDE': [], 'ADE': []}}\n",
    "    trajectron_ar3_results = {'BEST_OF_20': {'FDE': [], 'ADE': []}, 'MOST_LIKELY': {'FDE': [], 'ADE': []}}\n",
    "    cvm_long_results = {'BEST_OF_20': {'FDE': [], 'ADE': []}, 'MOST_LIKELY': {'FDE': [], 'ADE': []}}\n",
    "    cvm_short_results = {'BEST_OF_20': {'FDE': [], 'ADE': []}, 'MOST_LIKELY': {'FDE': [], 'ADE': []}}\n",
    "\n",
    "    for dataset_idx, dataset in enumerate(datasets):\n",
    "        our_fde_bo20, our_ade_bo20 = [], []\n",
    "        our_fde_most_likely, our_ade_most_likely = [], []\n",
    "        \n",
    "        cvm_fde_bo20, cvm_ade_bo20 = [], []\n",
    "        cvm_short_fde_bo20, cvm_short_ade_bo20 = [], []\n",
    "        \n",
    "        cvm_fde_ml, cvm_ade_ml = [], []\n",
    "        cvm_short_fde_ml, cvm_short_ade_ml = [], []\n",
    "        \n",
    "        for scene_idx, scene in enumerate(dataset):\n",
    "            data = pd.read_csv(base_path + scene, sep='\\t', index_col=False, header=None)\n",
    "            data.columns = ['frame_id', 'track_id', 'pos_x', 'pos_y']\n",
    "\n",
    "            data = process_data(data)\n",
    "\n",
    "            ## Ours\n",
    "            our_fde_best_of_20, our_ade_best_of_20, our_fde_single, our_ade_single = evaluate_our_method(data, our_method_params[dataset_idx], dataset_title=trajectron_resultset_names[dataset_idx], smoothing=False)\n",
    "            our_fde_bo20 += our_fde_best_of_20\n",
    "            our_ade_bo20 += our_ade_best_of_20\n",
    "            if evaluate_most_likely:\n",
    "                our_fde_most_likely += our_fde_single\n",
    "                our_ade_most_likely += our_ade_single\n",
    "\n",
    "            ## CVM\n",
    "            cvm_fde_best_of, cvm_ade_best_of = evaluate_cvm_with_scenarios(data, dataset_title=trajectron_resultset_names[dataset_idx])\n",
    "            cvm_fde_bo20 += cvm_fde_best_of\n",
    "            cvm_ade_bo20 += cvm_ade_best_of\n",
    "            \n",
    "            cvm_fde_short_history_best_of, cvm_ade_short_history_best_of = evaluate_cvm_with_scenarios(data, dataset_title=trajectron_resultset_names[dataset_idx], history_length=2)\n",
    "            cvm_short_fde_bo20 += cvm_fde_short_history_best_of\n",
    "            cvm_short_ade_bo20 += cvm_ade_short_history_best_of\n",
    "\n",
    "            if evaluate_most_likely:\n",
    "                cvm_fde, cvm_ade = evaluate_cvm(data, dataset_title=trajectron_resultset_names[dataset_idx])\n",
    "                cvm_fde_ml += cvm_fde\n",
    "                cvm_ade_ml += cvm_ade\n",
    "                \n",
    "                cvm_fde_short_history, cvm_ade_short_history = evaluate_cvm(data, dataset_title=trajectron_resultset_names[dataset_idx], history_length=2)\n",
    "                cvm_short_fde_ml += cvm_fde_short_history\n",
    "                cvm_short_ade_ml += cvm_ade_short_history\n",
    "\n",
    "        # add our and CVM results to the data dict\n",
    "        ours_results['BEST_OF_20']['FDE'].append(np.mean(our_fde_bo20))\n",
    "        ours_results['BEST_OF_20']['ADE'].append(np.mean(our_ade_bo20))\n",
    "        if evaluate_most_likely:\n",
    "            ours_results['MOST_LIKELY']['FDE'].append(np.mean(our_fde_most_likely))\n",
    "            ours_results['MOST_LIKELY']['ADE'].append(np.mean(our_ade_most_likely))\n",
    "            \n",
    "        cvm_long_results['BEST_OF_20']['FDE'].append(np.mean(cvm_fde_best_of))\n",
    "        cvm_long_results['BEST_OF_20']['ADE'].append(np.mean(cvm_ade_best_of))\n",
    "        cvm_short_results['BEST_OF_20']['FDE'].append(np.mean(cvm_fde_short_history_best_of))\n",
    "        cvm_short_results['BEST_OF_20']['ADE'].append(np.mean(cvm_ade_short_history_best_of))\n",
    "        if evaluate_most_likely:\n",
    "            cvm_long_results['MOST_LIKELY']['FDE'].append(np.mean(cvm_fde))\n",
    "            cvm_long_results['MOST_LIKELY']['ADE'].append(np.mean(cvm_ade))\n",
    "            cvm_short_results['MOST_LIKELY']['FDE'].append(np.mean(cvm_fde_short_history))\n",
    "            cvm_short_results['MOST_LIKELY']['ADE'].append(np.mean(cvm_ade_short_history))\n",
    "                \n",
    "        ## Trajectron\n",
    "        trajectron_fde, trajectron_ade = read_trajectron_data(trajectron_resultset_names[dataset_idx])\n",
    "        trajectron_results['BEST_OF_20']['FDE'].append(np.mean(trajectron_fde))\n",
    "        trajectron_results['BEST_OF_20']['ADE'].append(np.mean(trajectron_ade))\n",
    "        \n",
    "        if evaluate_most_likely:\n",
    "            trajectron_fde, trajectron_ade = read_trajectron_data(trajectron_resultset_names[dataset_idx], suffix='most_likely')\n",
    "            trajectron_results['MOST_LIKELY']['FDE'].append(np.mean(trajectron_fde))\n",
    "            trajectron_results['MOST_LIKELY']['ADE'].append(np.mean(trajectron_ade))\n",
    "        \n",
    "        ## Trajectron with interactions\n",
    "        if evaluate_with_interactions:\n",
    "            trajectron_ar3_fde, trajectron_ar3_ade = read_trajectron_data(trajectron_ar3_resultset_names[dataset_idx])\n",
    "            trajectron_ar3_results['BEST_OF_20']['FDE'].append(np.mean(trajectron_ar3_fde))\n",
    "            trajectron_ar3_results['BEST_OF_20']['ADE'].append(np.mean(trajectron_ar3_ade))\n",
    "\n",
    "            if evaluate_most_likely:\n",
    "                trajectron_ar3_fde, trajectron_ar3_ade = read_trajectron_data(trajectron_resultset_names[dataset_idx], suffix='most_likely')\n",
    "                trajectron_ar3_results['MOST_LIKELY']['FDE'].append(np.mean(trajectron_ar3_fde))\n",
    "                trajectron_ar3_results['MOST_LIKELY']['ADE'].append(np.mean(trajectron_ar3_ade))\n",
    "\n",
    "        # make sure that there is no discrepancy between our data processing and trajectron evaluation results size\n",
    "        if len(dataset) == 1:\n",
    "            num_predictable_trajectories = get_total_predictable_slices(data)\n",
    "            assert len(trajectron_fde) == num_predictable_trajectories\n",
    "            assert len(trajectron_ade) == num_predictable_trajectories\n",
    "    \n",
    "    return [\n",
    "        ours_results,\n",
    "        trajectron_results,\n",
    "        trajectron_ar3_results,\n",
    "        cvm_long_results,\n",
    "        cvm_short_results\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eac9d82",
   "metadata": {},
   "source": [
    "### Running the evaluation - BO20 params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a429d4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ours - eth_vel: 100%|█████████████████████████████████████████████████████████████████████████| 484/484 [00:39<00:00, 12.27it/s]\n",
      "CVM - eth_vel: 100%|█████████████████████████████████████████████████████████████████████████| 484/484 [00:01<00:00, 443.12it/s]\n",
      "CVM - eth_vel: 100%|█████████████████████████████████████████████████████████████████████████| 484/484 [00:00<00:00, 493.22it/s]\n",
      "CVM - eth_vel: 100%|█████████████████████████████████████████████████████████████████████████| 484/484 [00:00<00:00, 622.48it/s]\n",
      "CVM - eth_vel: 100%|█████████████████████████████████████████████████████████████████████████| 484/484 [00:00<00:00, 636.14it/s]\n",
      "Ours - hotel_vel: 100%|███████████████████████████████████████████████████████████████████████| 913/913 [01:55<00:00,  7.88it/s]\n",
      "CVM - hotel_vel: 100%|███████████████████████████████████████████████████████████████████████| 913/913 [00:03<00:00, 235.39it/s]\n",
      "CVM - hotel_vel: 100%|███████████████████████████████████████████████████████████████████████| 913/913 [00:03<00:00, 260.19it/s]\n",
      "CVM - hotel_vel: 100%|███████████████████████████████████████████████████████████████████████| 913/913 [00:02<00:00, 325.49it/s]\n",
      "CVM - hotel_vel: 100%|███████████████████████████████████████████████████████████████████████| 913/913 [00:02<00:00, 325.99it/s]\n",
      "Ours - univ_vel: 100%|████████████████████████████████████████████████████████████████████████| 444/444 [25:03<00:00,  3.39s/it]\n",
      "CVM - univ_vel: 100%|█████████████████████████████████████████████████████████████████████████| 444/444 [01:17<00:00,  5.76it/s]\n",
      "CVM - univ_vel: 100%|█████████████████████████████████████████████████████████████████████████| 444/444 [01:12<00:00,  6.12it/s]\n",
      "CVM - univ_vel: 100%|█████████████████████████████████████████████████████████████████████████| 444/444 [01:04<00:00,  6.90it/s]\n",
      "CVM - univ_vel: 100%|█████████████████████████████████████████████████████████████████████████| 444/444 [01:04<00:00,  6.89it/s]\n",
      "Ours - univ_vel: 100%|████████████████████████████████████████████████████████████████████████| 541/541 [17:28<00:00,  1.94s/it]\n",
      "CVM - univ_vel: 100%|█████████████████████████████████████████████████████████████████████████| 541/541 [00:50<00:00, 10.65it/s]\n",
      "CVM - univ_vel: 100%|█████████████████████████████████████████████████████████████████████████| 541/541 [00:47<00:00, 11.29it/s]\n",
      "CVM - univ_vel: 100%|█████████████████████████████████████████████████████████████████████████| 541/541 [00:41<00:00, 12.95it/s]\n",
      "CVM - univ_vel: 100%|█████████████████████████████████████████████████████████████████████████| 541/541 [00:41<00:00, 12.91it/s]\n",
      "Ours - zara1_vel_modified: 100%|██████████████████████████████████████████████████████████████| 864/864 [03:59<00:00,  3.61it/s]\n",
      "CVM - zara1_vel_modified: 100%|██████████████████████████████████████████████████████████████| 864/864 [00:07<00:00, 114.09it/s]\n",
      "CVM - zara1_vel_modified: 100%|██████████████████████████████████████████████████████████████| 864/864 [00:06<00:00, 128.05it/s]\n",
      "CVM - zara1_vel_modified: 100%|██████████████████████████████████████████████████████████████| 864/864 [00:05<00:00, 156.52it/s]\n",
      "CVM - zara1_vel_modified: 100%|██████████████████████████████████████████████████████████████| 864/864 [00:05<00:00, 145.07it/s]\n",
      "Ours - zara2_vel_modified: 100%|████████████████████████████████████████████████████████████| 1052/1052 [09:24<00:00,  1.86it/s]\n",
      "CVM - zara2_vel_modified: 100%|█████████████████████████████████████████████████████████████| 1052/1052 [00:21<00:00, 49.33it/s]\n",
      "CVM - zara2_vel_modified: 100%|█████████████████████████████████████████████████████████████| 1052/1052 [00:19<00:00, 54.13it/s]\n",
      "CVM - zara2_vel_modified: 100%|█████████████████████████████████████████████████████████████| 1052/1052 [00:16<00:00, 65.66it/s]\n",
      "CVM - zara2_vel_modified: 100%|█████████████████████████████████████████████████████████████| 1052/1052 [00:15<00:00, 65.77it/s]\n"
     ]
    }
   ],
   "source": [
    "eth_params = {\n",
    "    'NOISE': 0.05, \n",
    "    'NO_OF_TRAJECTORIES': 500, \n",
    "    'CONST_VEL_MODEL_PROB': 0.5, \n",
    "    'STOP_PROB': 0.025, \n",
    "    'DISCOUNT_AVG_PROB': 1.0, \n",
    "    'DISCOUNT_LOWER_BOUND': 0.15, \n",
    "    'VELOCITY_CHANGE_PROB': 0.1,\n",
    "    'VELOCITY_CHANGE_NOISE': 0.1, \n",
    "    'ANGLE_CHANGE_PROB': 0.2, \n",
    "    'ANGLE_CHANGE_NOISE': 2, \n",
    "    'GROUP_PERCENTAGES': [0.1, 0.5, 0.75, 1.0], \n",
    "    'GROUP_CLUSTER_COUNT': [1, 9, 6, 4]\n",
    "}\n",
    "\n",
    "hotel_params = {\n",
    "    'NOISE': 0.05, \n",
    "    'NO_OF_TRAJECTORIES': 500, \n",
    "    'CONST_VEL_MODEL_PROB': 0.5, \n",
    "    'STOP_PROB': 0.0, \n",
    "    'DISCOUNT_AVG_PROB': 1.0, \n",
    "    'DISCOUNT_LOWER_BOUND': 0.1, \n",
    "    'VELOCITY_CHANGE_PROB': 0.1,\n",
    "    'VELOCITY_CHANGE_NOISE': 0.1, \n",
    "    'ANGLE_CHANGE_PROB': 0.2, \n",
    "    'ANGLE_CHANGE_NOISE': 2, \n",
    "    'GROUP_PERCENTAGES': [0.1, 0.60, 1.0], \n",
    "    'GROUP_CLUSTER_COUNT': [1, 11, 8]\n",
    "}\n",
    "\n",
    "zara1_params = {\n",
    "    'NOISE': 0.05, \n",
    "    'NO_OF_TRAJECTORIES': 500, \n",
    "    'CONST_VEL_MODEL_PROB': 0.5, \n",
    "    'STOP_PROB': 0.0, \n",
    "    'DISCOUNT_AVG_PROB': 1.0, \n",
    "    'DISCOUNT_LOWER_BOUND': 0.2, \n",
    "    'VELOCITY_CHANGE_PROB': 0.1,\n",
    "    'VELOCITY_CHANGE_NOISE': 0.1, \n",
    "    'ANGLE_CHANGE_PROB': 0.2, \n",
    "    'ANGLE_CHANGE_NOISE': 2, \n",
    "    'GROUP_PERCENTAGES': [0.1, 0.60, 1.0], \n",
    "    'GROUP_CLUSTER_COUNT': [1, 14, 5]\n",
    "}\n",
    "\n",
    "zara2_params = {\n",
    "    'NOISE': 0.1, \n",
    "    'NO_OF_TRAJECTORIES': 500, \n",
    "    'CONST_VEL_MODEL_PROB': 0.5, \n",
    "    'STOP_PROB': 0.025, \n",
    "    'DISCOUNT_AVG_PROB': 1.0, \n",
    "    'DISCOUNT_LOWER_BOUND': 0.2, \n",
    "    'VELOCITY_CHANGE_PROB': 0.1,\n",
    "    'VELOCITY_CHANGE_NOISE': 0.1, \n",
    "    'ANGLE_CHANGE_PROB': 0.1, \n",
    "    'ANGLE_CHANGE_NOISE': 2, \n",
    "    'GROUP_PERCENTAGES': [0.1, 0.60, 1.0], \n",
    "    'GROUP_CLUSTER_COUNT': [1, 14, 5]\n",
    "}\n",
    "\n",
    "univ_params = {\n",
    "    'NOISE': 0.025, \n",
    "    'NO_OF_TRAJECTORIES': 500, \n",
    "    'CONST_VEL_MODEL_PROB': 0.5, \n",
    "    'STOP_PROB': 0.05, \n",
    "    'DISCOUNT_AVG_PROB': 1.0, \n",
    "    'DISCOUNT_LOWER_BOUND': 0.1, \n",
    "    'VELOCITY_CHANGE_PROB': 0.1,\n",
    "    'VELOCITY_CHANGE_NOISE': 0.1, \n",
    "    'ANGLE_CHANGE_PROB': 0.2, \n",
    "    'ANGLE_CHANGE_NOISE': 2, \n",
    "    'GROUP_PERCENTAGES': [0.1, 0.5, 0.75, 1.0], \n",
    "    'GROUP_CLUSTER_COUNT': [1, 9, 6, 4]\n",
    "}\n",
    "\n",
    "\n",
    "our_method_params = [eth_params, hotel_params, univ_params, zara1_params, zara2_params]\n",
    "\n",
    "datasets = [\n",
    "    ['eth/test/biwi_eth.txt'], \n",
    "    ['hotel/test/biwi_hotel.txt'], \n",
    "    ['univ/test/students001.txt', 'univ/test/students003.txt'],\n",
    "    ['zara1/test/crowds_zara01.txt'], \n",
    "    ['zara2/test/crowds_zara02.txt'],\n",
    "]\n",
    "\n",
    "trajectron_resultset_names = [\n",
    "    'eth_vel', \n",
    "    'hotel_vel',\n",
    "    'univ_vel',\n",
    "    'zara1_vel_modified', \n",
    "    'zara2_vel_modified',\n",
    "]\n",
    "\n",
    "trajectron_ar3_resultset_names = [\n",
    "    'eth_ar3', \n",
    "    'hotel_ar3', \n",
    "    'univ_ar3',\n",
    "    'zara1_ar3', \n",
    "    'zara2_ar3',\n",
    "]\n",
    "\n",
    "res = evaluate_all_datasets(our_method_params, datasets, trajectron_resultset_names, trajectron_ar3_resultset_names, evaluate_most_likely=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7260ac78",
   "metadata": {},
   "outputs": [],
   "source": [
    "ours_results = res[0]\n",
    "trajectron_results = res[1]\n",
    "trajectron_ar3_results = res[2]\n",
    "cvm_long_results = res[3]\n",
    "cvm_short_results = res[4]\n",
    "\n",
    "sgan_results = {\n",
    "    'BEST_OF_20': {\n",
    "        'FDE': [1.52, 1.61, 0.69, 1.26, 0.84], \n",
    "        'ADE': [0.81, 0.72, 0.60, 0.34, 0.42]\n",
    "    }, \n",
    "    'MOST_LIKELY': {\n",
    "        'FDE': [2.21, 2.18, 1.28, 0.91, 1.11], \n",
    "        'ADE': [ 1.13, 1.01, 0.60, 0.42, 0.52]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab25de20",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [\n",
    "    'ETH', \n",
    "    'Hotel', \n",
    "    'Univ',\n",
    "    'Zara 1', \n",
    "    'Zara 2',\n",
    "    \n",
    "]\n",
    "\n",
    "df_data_best_of_20_fde = {\n",
    "    'CVM (8pt history)' : pd.Series(cvm_long_results['BEST_OF_20']['FDE'], index = index),\n",
    "    'CVM (2pt history)' : pd.Series(cvm_short_results['BEST_OF_20']['FDE'], index = index),\n",
    "    'Social-GAN': pd.Series(sgan_results['BEST_OF_20']['FDE'], index = index),\n",
    "    'Trajectron++' : pd.Series(trajectron_results['BEST_OF_20']['FDE'], index = index),\n",
    "    #'Trajectron++ AR3' : pd.Series(trajectron_ar3_results['BEST_OF_20']['FDE'], index = index),\n",
    "    'Ours': pd.Series(ours_results['BEST_OF_20']['FDE'], index = index)\n",
    "}\n",
    "\n",
    "df_best_of_20_fde = pd.DataFrame(df_data_best_of_20_fde)\n",
    "df_best_of_20_fde.loc['Average'] = df_best_of_20_fde.mean()\n",
    "\n",
    "df_data_best_of_20_ade = {\n",
    "    'CVM (8pt history)' : pd.Series(cvm_long_results['BEST_OF_20']['ADE'], index = index),\n",
    "    'CVM (2pt history)' : pd.Series(cvm_short_results['BEST_OF_20']['ADE'], index = index),\n",
    "    'Social-GAN': pd.Series(sgan_results['BEST_OF_20']['ADE'], index = index),\n",
    "    'Trajectron++' : pd.Series(trajectron_results['BEST_OF_20']['ADE'], index = index),\n",
    "    #'Trajectron++ AR3' : pd.Series(trajectron_ar3_results['BEST_OF_20']['ADE'], index = index),\n",
    "    'Ours': pd.Series(ours_results['BEST_OF_20']['ADE'], index = index)\n",
    "}\n",
    "\n",
    "df_best_of_20_ade = pd.DataFrame(df_data_best_of_20_ade)\n",
    "df_best_of_20_ade.loc['Average'] = df_best_of_20_ade.mean()\n",
    "\n",
    "df_data_most_likely_fde = {\n",
    "    'CVM (8pt history)' : pd.Series(cvm_long_results['MOST_LIKELY']['FDE'], index = index),\n",
    "    'CVM (2pt history)' : pd.Series(cvm_short_results['MOST_LIKELY']['FDE'], index = index),\n",
    "    'Social-GAN': pd.Series(sgan_results['MOST_LIKELY']['FDE'], index = index),\n",
    "    'Trajectron++' : pd.Series(trajectron_results['MOST_LIKELY']['FDE'], index = index),\n",
    "    #'Trajectron++ AR3' : pd.Series(trajectron_ar3_results['MOST_LIKELY']['FDE'], index = index),\n",
    "    'Ours': pd.Series(ours_results['MOST_LIKELY']['FDE'], index = index)\n",
    "}\n",
    "\n",
    "df_most_likely_fde = pd.DataFrame(df_data_most_likely_fde)\n",
    "df_most_likely_fde.loc['Average'] = df_most_likely_fde.mean()\n",
    "\n",
    "df_data_most_likely_ade = {\n",
    "    'CVM (8pt history)' : pd.Series(cvm_long_results['MOST_LIKELY']['ADE'], index = index),\n",
    "    'CVM (2pt history)' : pd.Series(cvm_short_results['MOST_LIKELY']['ADE'], index = index),\n",
    "    'Social-GAN': pd.Series(sgan_results['MOST_LIKELY']['ADE'], index = index),\n",
    "    'Trajectron++' : pd.Series(trajectron_results['MOST_LIKELY']['ADE'], index = index),\n",
    "    #'Trajectron++ AR3' : pd.Series(trajectron_ar3_results['MOST_LIKELY']['ADE'], index = index),\n",
    "    'Ours': pd.Series(ours_results['MOST_LIKELY']['ADE'], index = index)\n",
    "}\n",
    "\n",
    "df_most_likely_ade = pd.DataFrame(df_data_most_likely_ade)\n",
    "df_most_likely_ade.loc['Average'] = df_most_likely_ade.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f64a9ed",
   "metadata": {},
   "source": [
    "### Best of 20 - FDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f50969a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7ea75_row0_col4, #T_7ea75_row1_col4, #T_7ea75_row2_col4, #T_7ea75_row3_col3, #T_7ea75_row4_col3, #T_7ea75_row5_col4 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7ea75_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >CVM (8pt history)</th>\n",
       "      <th class=\"col_heading level0 col1\" >CVM (2pt history)</th>\n",
       "      <th class=\"col_heading level0 col2\" >Social-GAN</th>\n",
       "      <th class=\"col_heading level0 col3\" >Trajectron++</th>\n",
       "      <th class=\"col_heading level0 col4\" >Ours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7ea75_level0_row0\" class=\"row_heading level0 row0\" >ETH</th>\n",
       "      <td id=\"T_7ea75_row0_col0\" class=\"data row0 col0\" >1.136</td>\n",
       "      <td id=\"T_7ea75_row0_col1\" class=\"data row0 col1\" >1.703</td>\n",
       "      <td id=\"T_7ea75_row0_col2\" class=\"data row0 col2\" >1.520</td>\n",
       "      <td id=\"T_7ea75_row0_col3\" class=\"data row0 col3\" >0.812</td>\n",
       "      <td id=\"T_7ea75_row0_col4\" class=\"data row0 col4\" >0.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ea75_level0_row1\" class=\"row_heading level0 row1\" >Hotel</th>\n",
       "      <td id=\"T_7ea75_row1_col0\" class=\"data row1 col0\" >0.363</td>\n",
       "      <td id=\"T_7ea75_row1_col1\" class=\"data row1 col1\" >0.580</td>\n",
       "      <td id=\"T_7ea75_row1_col2\" class=\"data row1 col2\" >1.610</td>\n",
       "      <td id=\"T_7ea75_row1_col3\" class=\"data row1 col3\" >0.197</td>\n",
       "      <td id=\"T_7ea75_row1_col4\" class=\"data row1 col4\" >0.184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ea75_level0_row2\" class=\"row_heading level0 row2\" >Univ</th>\n",
       "      <td id=\"T_7ea75_row2_col0\" class=\"data row2 col0\" >0.965</td>\n",
       "      <td id=\"T_7ea75_row2_col1\" class=\"data row2 col1\" >1.216</td>\n",
       "      <td id=\"T_7ea75_row2_col2\" class=\"data row2 col2\" >0.690</td>\n",
       "      <td id=\"T_7ea75_row2_col3\" class=\"data row2 col3\" >0.450</td>\n",
       "      <td id=\"T_7ea75_row2_col4\" class=\"data row2 col4\" >0.447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ea75_level0_row3\" class=\"row_heading level0 row3\" >Zara 1</th>\n",
       "      <td id=\"T_7ea75_row3_col0\" class=\"data row3 col0\" >0.791</td>\n",
       "      <td id=\"T_7ea75_row3_col1\" class=\"data row3 col1\" >0.874</td>\n",
       "      <td id=\"T_7ea75_row3_col2\" class=\"data row3 col2\" >1.260</td>\n",
       "      <td id=\"T_7ea75_row3_col3\" class=\"data row3 col3\" >0.342</td>\n",
       "      <td id=\"T_7ea75_row3_col4\" class=\"data row3 col4\" >0.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ea75_level0_row4\" class=\"row_heading level0 row4\" >Zara 2</th>\n",
       "      <td id=\"T_7ea75_row4_col0\" class=\"data row4 col0\" >0.560</td>\n",
       "      <td id=\"T_7ea75_row4_col1\" class=\"data row4 col1\" >0.656</td>\n",
       "      <td id=\"T_7ea75_row4_col2\" class=\"data row4 col2\" >0.840</td>\n",
       "      <td id=\"T_7ea75_row4_col3\" class=\"data row4 col3\" >0.253</td>\n",
       "      <td id=\"T_7ea75_row4_col4\" class=\"data row4 col4\" >0.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7ea75_level0_row5\" class=\"row_heading level0 row5\" >Average</th>\n",
       "      <td id=\"T_7ea75_row5_col0\" class=\"data row5 col0\" >0.763</td>\n",
       "      <td id=\"T_7ea75_row5_col1\" class=\"data row5 col1\" >1.006</td>\n",
       "      <td id=\"T_7ea75_row5_col2\" class=\"data row5 col2\" >1.184</td>\n",
       "      <td id=\"T_7ea75_row5_col3\" class=\"data row5 col3\" >0.411</td>\n",
       "      <td id=\"T_7ea75_row5_col4\" class=\"data row5 col4\" >0.403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x135fd81f0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K-means without smoothing\n",
    "df_best_of_20_fde.style.highlight_min(color = 'lightgreen', axis = 1).format(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48902f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "{} & {CVM (8pt history)} & {CVM (2pt history)} & {Social-GAN} & {Trajectron++} & {Ours} \\\\\n",
      "\\midrule\n",
      "ETH & 1.136 & 1.703 & 1.520 & 0.812 & \\textbf{0.650} \\\\\n",
      "Hotel & 0.363 & 0.580 & 1.610 & 0.197 & \\textbf{0.184} \\\\\n",
      "Univ & 0.965 & 1.216 & 0.690 & 0.450 & \\textbf{0.447} \\\\\n",
      "Zara 1 & 0.791 & 0.874 & 1.260 & \\textbf{0.342} & 0.421 \\\\\n",
      "Zara 2 & 0.560 & 0.656 & 0.840 & \\textbf{0.253} & 0.311 \\\\\n",
      "Average & 0.763 & 1.006 & 1.184 & 0.411 & \\textbf{0.403} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print(df_best_of_20_fde.to_latex(header=False))\n",
    "\n",
    "print(df_best_of_20_fde.style.highlight_min(props='textbf:--rwrap', axis=1).format(precision=3).to_latex(hrules=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2296114d",
   "metadata": {},
   "source": [
    "### Best of 20 - ADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25a02de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_82806_row0_col3, #T_82806_row1_col3, #T_82806_row2_col3, #T_82806_row3_col3, #T_82806_row4_col3, #T_82806_row5_col3 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_82806_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >CVM (8pt history)</th>\n",
       "      <th class=\"col_heading level0 col1\" >CVM (2pt history)</th>\n",
       "      <th class=\"col_heading level0 col2\" >Social-GAN</th>\n",
       "      <th class=\"col_heading level0 col3\" >Trajectron++</th>\n",
       "      <th class=\"col_heading level0 col4\" >Ours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_82806_level0_row0\" class=\"row_heading level0 row0\" >ETH</th>\n",
       "      <td id=\"T_82806_row0_col0\" class=\"data row0 col0\" >0.643</td>\n",
       "      <td id=\"T_82806_row0_col1\" class=\"data row0 col1\" >0.873</td>\n",
       "      <td id=\"T_82806_row0_col2\" class=\"data row0 col2\" >0.810</td>\n",
       "      <td id=\"T_82806_row0_col3\" class=\"data row0 col3\" >0.396</td>\n",
       "      <td id=\"T_82806_row0_col4\" class=\"data row0 col4\" >0.445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82806_level0_row1\" class=\"row_heading level0 row1\" >Hotel</th>\n",
       "      <td id=\"T_82806_row1_col0\" class=\"data row1 col0\" >0.205</td>\n",
       "      <td id=\"T_82806_row1_col1\" class=\"data row1 col1\" >0.306</td>\n",
       "      <td id=\"T_82806_row1_col2\" class=\"data row1 col2\" >0.720</td>\n",
       "      <td id=\"T_82806_row1_col3\" class=\"data row1 col3\" >0.115</td>\n",
       "      <td id=\"T_82806_row1_col4\" class=\"data row1 col4\" >0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82806_level0_row2\" class=\"row_heading level0 row2\" >Univ</th>\n",
       "      <td id=\"T_82806_row2_col0\" class=\"data row2 col0\" >0.525</td>\n",
       "      <td id=\"T_82806_row2_col1\" class=\"data row2 col1\" >0.571</td>\n",
       "      <td id=\"T_82806_row2_col2\" class=\"data row2 col2\" >0.600</td>\n",
       "      <td id=\"T_82806_row2_col3\" class=\"data row2 col3\" >0.205</td>\n",
       "      <td id=\"T_82806_row2_col4\" class=\"data row2 col4\" >0.269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82806_level0_row3\" class=\"row_heading level0 row3\" >Zara 1</th>\n",
       "      <td id=\"T_82806_row3_col0\" class=\"data row3 col0\" >0.413</td>\n",
       "      <td id=\"T_82806_row3_col1\" class=\"data row3 col1\" >0.404</td>\n",
       "      <td id=\"T_82806_row3_col2\" class=\"data row3 col2\" >0.340</td>\n",
       "      <td id=\"T_82806_row3_col3\" class=\"data row3 col3\" >0.155</td>\n",
       "      <td id=\"T_82806_row3_col4\" class=\"data row3 col4\" >0.257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82806_level0_row4\" class=\"row_heading level0 row4\" >Zara 2</th>\n",
       "      <td id=\"T_82806_row4_col0\" class=\"data row4 col0\" >0.299</td>\n",
       "      <td id=\"T_82806_row4_col1\" class=\"data row4 col1\" >0.305</td>\n",
       "      <td id=\"T_82806_row4_col2\" class=\"data row4 col2\" >0.420</td>\n",
       "      <td id=\"T_82806_row4_col3\" class=\"data row4 col3\" >0.115</td>\n",
       "      <td id=\"T_82806_row4_col4\" class=\"data row4 col4\" >0.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82806_level0_row5\" class=\"row_heading level0 row5\" >Average</th>\n",
       "      <td id=\"T_82806_row5_col0\" class=\"data row5 col0\" >0.417</td>\n",
       "      <td id=\"T_82806_row5_col1\" class=\"data row5 col1\" >0.492</td>\n",
       "      <td id=\"T_82806_row5_col2\" class=\"data row5 col2\" >0.578</td>\n",
       "      <td id=\"T_82806_row5_col3\" class=\"data row5 col3\" >0.197</td>\n",
       "      <td id=\"T_82806_row5_col4\" class=\"data row5 col4\" >0.257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x135fd8160>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K-means without smoothing\n",
    "df_best_of_20_ade.style.highlight_min(color = 'lightgreen', axis = 1).format(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7013fdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "{} & {CVM (8pt history)} & {CVM (2pt history)} & {Social-GAN} & {Trajectron++} & {Ours} \\\\\n",
      "ETH & 0.643 & 0.873 & 0.810 & \\textbf{0.396} & 0.445 \\\\\n",
      "Hotel & 0.205 & 0.306 & 0.720 & \\textbf{0.115} & 0.125 \\\\\n",
      "Univ & 0.525 & 0.571 & 0.600 & \\textbf{0.205} & 0.269 \\\\\n",
      "Zara 1 & 0.413 & 0.404 & 0.340 & \\textbf{0.155} & 0.257 \\\\\n",
      "Zara 2 & 0.299 & 0.305 & 0.420 & \\textbf{0.115} & 0.187 \\\\\n",
      "Average & 0.417 & 0.492 & 0.578 & \\textbf{0.197} & 0.257 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_best_of_20_ade.style.highlight_min(props='textbf:--rwrap', axis=1).format(precision=3).to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cee6f79",
   "metadata": {},
   "source": [
    "### Single output - FDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c3796e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f8ad7_row0_col3, #T_f8ad7_row1_col4, #T_f8ad7_row2_col4, #T_f8ad7_row3_col3, #T_f8ad7_row4_col3, #T_f8ad7_row5_col3 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f8ad7_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >CVM (8pt history)</th>\n",
       "      <th class=\"col_heading level0 col1\" >CVM (2pt history)</th>\n",
       "      <th class=\"col_heading level0 col2\" >Social-GAN</th>\n",
       "      <th class=\"col_heading level0 col3\" >Trajectron++</th>\n",
       "      <th class=\"col_heading level0 col4\" >Ours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f8ad7_level0_row0\" class=\"row_heading level0 row0\" >ETH</th>\n",
       "      <td id=\"T_f8ad7_row0_col0\" class=\"data row0 col0\" >2.303</td>\n",
       "      <td id=\"T_f8ad7_row0_col1\" class=\"data row0 col1\" >2.282</td>\n",
       "      <td id=\"T_f8ad7_row0_col2\" class=\"data row0 col2\" >2.210</td>\n",
       "      <td id=\"T_f8ad7_row0_col3\" class=\"data row0 col3\" >1.615</td>\n",
       "      <td id=\"T_f8ad7_row0_col4\" class=\"data row0 col4\" >2.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f8ad7_level0_row1\" class=\"row_heading level0 row1\" >Hotel</th>\n",
       "      <td id=\"T_f8ad7_row1_col0\" class=\"data row1 col0\" >0.462</td>\n",
       "      <td id=\"T_f8ad7_row1_col1\" class=\"data row1 col1\" >0.614</td>\n",
       "      <td id=\"T_f8ad7_row1_col2\" class=\"data row1 col2\" >2.180</td>\n",
       "      <td id=\"T_f8ad7_row1_col3\" class=\"data row1 col3\" >0.499</td>\n",
       "      <td id=\"T_f8ad7_row1_col4\" class=\"data row1 col4\" >0.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f8ad7_level0_row2\" class=\"row_heading level0 row2\" >Univ</th>\n",
       "      <td id=\"T_f8ad7_row2_col0\" class=\"data row2 col0\" >1.576</td>\n",
       "      <td id=\"T_f8ad7_row2_col1\" class=\"data row2 col1\" >1.369</td>\n",
       "      <td id=\"T_f8ad7_row2_col2\" class=\"data row2 col2\" >1.280</td>\n",
       "      <td id=\"T_f8ad7_row2_col3\" class=\"data row2 col3\" >1.205</td>\n",
       "      <td id=\"T_f8ad7_row2_col4\" class=\"data row2 col4\" >1.196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f8ad7_level0_row3\" class=\"row_heading level0 row3\" >Zara 1</th>\n",
       "      <td id=\"T_f8ad7_row3_col0\" class=\"data row3 col0\" >1.132</td>\n",
       "      <td id=\"T_f8ad7_row3_col1\" class=\"data row3 col1\" >0.952</td>\n",
       "      <td id=\"T_f8ad7_row3_col2\" class=\"data row3 col2\" >0.910</td>\n",
       "      <td id=\"T_f8ad7_row3_col3\" class=\"data row3 col3\" >0.770</td>\n",
       "      <td id=\"T_f8ad7_row3_col4\" class=\"data row3 col4\" >1.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f8ad7_level0_row4\" class=\"row_heading level0 row4\" >Zara 2</th>\n",
       "      <td id=\"T_f8ad7_row4_col0\" class=\"data row4 col0\" >0.860</td>\n",
       "      <td id=\"T_f8ad7_row4_col1\" class=\"data row4 col1\" >0.724</td>\n",
       "      <td id=\"T_f8ad7_row4_col2\" class=\"data row4 col2\" >1.110</td>\n",
       "      <td id=\"T_f8ad7_row4_col3\" class=\"data row4 col3\" >0.589</td>\n",
       "      <td id=\"T_f8ad7_row4_col4\" class=\"data row4 col4\" >0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f8ad7_level0_row5\" class=\"row_heading level0 row5\" >Average</th>\n",
       "      <td id=\"T_f8ad7_row5_col0\" class=\"data row5 col0\" >1.267</td>\n",
       "      <td id=\"T_f8ad7_row5_col1\" class=\"data row5 col1\" >1.188</td>\n",
       "      <td id=\"T_f8ad7_row5_col2\" class=\"data row5 col2\" >1.538</td>\n",
       "      <td id=\"T_f8ad7_row5_col3\" class=\"data row5 col3\" >0.936</td>\n",
       "      <td id=\"T_f8ad7_row5_col4\" class=\"data row5 col4\" >1.082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x135fd8e20>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_most_likely_fde.style.highlight_min(color = 'lightgreen', axis = 1).format(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98673b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "{} & {CVM (8pt history)} & {CVM (2pt history)} & {Social-GAN} & {Trajectron++} & {Ours} \\\\\n",
      "ETH & 2.303 & 2.282 & 2.210 & \\textbf{1.615} & 2.019 \\\\\n",
      "Hotel & 0.462 & 0.614 & 2.180 & 0.499 & \\textbf{0.401} \\\\\n",
      "Univ & 1.576 & 1.369 & 1.280 & 1.205 & \\textbf{1.196} \\\\\n",
      "Zara 1 & 1.132 & 0.952 & 0.910 & \\textbf{0.770} & 1.016 \\\\\n",
      "Zara 2 & 0.860 & 0.724 & 1.110 & \\textbf{0.589} & 0.780 \\\\\n",
      "Average & 1.267 & 1.188 & 1.538 & \\textbf{0.936} & 1.082 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_most_likely_fde.style.highlight_min(props='textbf:--rwrap', axis=1).format(precision=3).to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e3ac08",
   "metadata": {},
   "source": [
    "### Single output - ADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ff1e486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_562a3_row0_col3, #T_562a3_row1_col4, #T_562a3_row2_col3, #T_562a3_row3_col3, #T_562a3_row4_col3, #T_562a3_row5_col3 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_562a3_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >CVM (8pt history)</th>\n",
       "      <th class=\"col_heading level0 col1\" >CVM (2pt history)</th>\n",
       "      <th class=\"col_heading level0 col2\" >Social-GAN</th>\n",
       "      <th class=\"col_heading level0 col3\" >Trajectron++</th>\n",
       "      <th class=\"col_heading level0 col4\" >Ours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_562a3_level0_row0\" class=\"row_heading level0 row0\" >ETH</th>\n",
       "      <td id=\"T_562a3_row0_col0\" class=\"data row0 col0\" >1.102</td>\n",
       "      <td id=\"T_562a3_row0_col1\" class=\"data row0 col1\" >1.075</td>\n",
       "      <td id=\"T_562a3_row0_col2\" class=\"data row0 col2\" >1.130</td>\n",
       "      <td id=\"T_562a3_row0_col3\" class=\"data row0 col3\" >0.695</td>\n",
       "      <td id=\"T_562a3_row0_col4\" class=\"data row0 col4\" >0.953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_562a3_level0_row1\" class=\"row_heading level0 row1\" >Hotel</th>\n",
       "      <td id=\"T_562a3_row1_col0\" class=\"data row1 col0\" >0.243</td>\n",
       "      <td id=\"T_562a3_row1_col1\" class=\"data row1 col1\" >0.319</td>\n",
       "      <td id=\"T_562a3_row1_col2\" class=\"data row1 col2\" >1.010</td>\n",
       "      <td id=\"T_562a3_row1_col3\" class=\"data row1 col3\" >0.224</td>\n",
       "      <td id=\"T_562a3_row1_col4\" class=\"data row1 col4\" >0.213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_562a3_level0_row2\" class=\"row_heading level0 row2\" >Univ</th>\n",
       "      <td id=\"T_562a3_row2_col0\" class=\"data row2 col0\" >0.781</td>\n",
       "      <td id=\"T_562a3_row2_col1\" class=\"data row2 col1\" >0.618</td>\n",
       "      <td id=\"T_562a3_row2_col2\" class=\"data row2 col2\" >0.600</td>\n",
       "      <td id=\"T_562a3_row2_col3\" class=\"data row2 col3\" >0.468</td>\n",
       "      <td id=\"T_562a3_row2_col4\" class=\"data row2 col4\" >0.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_562a3_level0_row3\" class=\"row_heading level0 row3\" >Zara 1</th>\n",
       "      <td id=\"T_562a3_row3_col0\" class=\"data row3 col0\" >0.552</td>\n",
       "      <td id=\"T_562a3_row3_col1\" class=\"data row3 col1\" >0.427</td>\n",
       "      <td id=\"T_562a3_row3_col2\" class=\"data row3 col2\" >0.420</td>\n",
       "      <td id=\"T_562a3_row3_col3\" class=\"data row3 col3\" >0.297</td>\n",
       "      <td id=\"T_562a3_row3_col4\" class=\"data row3 col4\" >0.483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_562a3_level0_row4\" class=\"row_heading level0 row4\" >Zara 2</th>\n",
       "      <td id=\"T_562a3_row4_col0\" class=\"data row4 col0\" >0.421</td>\n",
       "      <td id=\"T_562a3_row4_col1\" class=\"data row4 col1\" >0.324</td>\n",
       "      <td id=\"T_562a3_row4_col2\" class=\"data row4 col2\" >0.520</td>\n",
       "      <td id=\"T_562a3_row4_col3\" class=\"data row4 col3\" >0.227</td>\n",
       "      <td id=\"T_562a3_row4_col4\" class=\"data row4 col4\" >0.381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_562a3_level0_row5\" class=\"row_heading level0 row5\" >Average</th>\n",
       "      <td id=\"T_562a3_row5_col0\" class=\"data row5 col0\" >0.620</td>\n",
       "      <td id=\"T_562a3_row5_col1\" class=\"data row5 col1\" >0.553</td>\n",
       "      <td id=\"T_562a3_row5_col2\" class=\"data row5 col2\" >0.736</td>\n",
       "      <td id=\"T_562a3_row5_col3\" class=\"data row5 col3\" >0.382</td>\n",
       "      <td id=\"T_562a3_row5_col4\" class=\"data row5 col4\" >0.520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x107eaa6d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_most_likely_ade.style.highlight_min(color = 'lightgreen', axis = 1).format(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b0ce958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "{} & {CVM (8pt history)} & {CVM (2pt history)} & {Social-GAN} & {Trajectron++} & {Ours} \\\\\n",
      "ETH & 1.102 & 1.075 & 1.130 & \\textbf{0.695} & 0.953 \\\\\n",
      "Hotel & 0.243 & 0.319 & 1.010 & 0.224 & \\textbf{0.213} \\\\\n",
      "Univ & 0.781 & 0.618 & 0.600 & \\textbf{0.468} & 0.570 \\\\\n",
      "Zara 1 & 0.552 & 0.427 & 0.420 & \\textbf{0.297} & 0.483 \\\\\n",
      "Zara 2 & 0.421 & 0.324 & 0.520 & \\textbf{0.227} & 0.381 \\\\\n",
      "Average & 0.620 & 0.553 & 0.736 & \\textbf{0.382} & 0.520 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_most_likely_ade.style.highlight_min(props='textbf:--rwrap', axis=1).format(precision=3).to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9374861",
   "metadata": {},
   "source": [
    "### Running the evaluation - most likely / single pred params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "72f8ebb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ours - eth_vel: 100%|█████████████████████████████████████████████████████████████████████████| 484/484 [00:23<00:00, 20.51it/s]\n",
      "CVM - eth_vel: 100%|█████████████████████████████████████████████████████████████████████████| 484/484 [00:01<00:00, 477.05it/s]\n",
      "CVM - eth_vel: 100%|█████████████████████████████████████████████████████████████████████████| 484/484 [00:00<00:00, 537.63it/s]\n",
      "CVM - eth_vel: 100%|█████████████████████████████████████████████████████████████████████████| 484/484 [00:00<00:00, 703.48it/s]\n",
      "CVM - eth_vel: 100%|█████████████████████████████████████████████████████████████████████████| 484/484 [00:00<00:00, 702.83it/s]\n",
      "Ours - hotel_vel: 100%|███████████████████████████████████████████████████████████████████████| 913/913 [01:18<00:00, 11.69it/s]\n",
      "CVM - hotel_vel: 100%|███████████████████████████████████████████████████████████████████████| 913/913 [00:03<00:00, 242.67it/s]\n",
      "CVM - hotel_vel: 100%|███████████████████████████████████████████████████████████████████████| 913/913 [00:03<00:00, 265.70it/s]\n",
      "CVM - hotel_vel: 100%|███████████████████████████████████████████████████████████████████████| 913/913 [00:02<00:00, 332.39it/s]\n",
      "CVM - hotel_vel: 100%|███████████████████████████████████████████████████████████████████████| 913/913 [00:02<00:00, 329.14it/s]\n",
      "Ours - univ_vel: 100%|████████████████████████████████████████████████████████████████████████| 444/444 [15:38<00:00,  2.11s/it]\n",
      "CVM - univ_vel: 100%|█████████████████████████████████████████████████████████████████████████| 444/444 [01:15<00:00,  5.84it/s]\n",
      "CVM - univ_vel: 100%|█████████████████████████████████████████████████████████████████████████| 444/444 [01:12<00:00,  6.15it/s]\n",
      "CVM - univ_vel: 100%|█████████████████████████████████████████████████████████████████████████| 444/444 [01:03<00:00,  7.04it/s]\n",
      "CVM - univ_vel: 100%|█████████████████████████████████████████████████████████████████████████| 444/444 [01:03<00:00,  7.05it/s]\n",
      "Ours - univ_vel: 100%|████████████████████████████████████████████████████████████████████████| 541/541 [11:01<00:00,  1.22s/it]\n",
      "CVM - univ_vel: 100%|█████████████████████████████████████████████████████████████████████████| 541/541 [00:49<00:00, 10.94it/s]\n",
      "CVM - univ_vel: 100%|█████████████████████████████████████████████████████████████████████████| 541/541 [00:46<00:00, 11.66it/s]\n",
      "CVM - univ_vel: 100%|█████████████████████████████████████████████████████████████████████████| 541/541 [00:40<00:00, 13.39it/s]\n",
      "CVM - univ_vel: 100%|█████████████████████████████████████████████████████████████████████████| 541/541 [00:40<00:00, 13.29it/s]\n",
      "Ours - zara1_vel_modified: 100%|██████████████████████████████████████████████████████████████| 864/864 [02:31<00:00,  5.70it/s]\n",
      "CVM - zara1_vel_modified: 100%|██████████████████████████████████████████████████████████████| 864/864 [00:07<00:00, 121.06it/s]\n",
      "CVM - zara1_vel_modified: 100%|██████████████████████████████████████████████████████████████| 864/864 [00:06<00:00, 135.52it/s]\n",
      "CVM - zara1_vel_modified: 100%|██████████████████████████████████████████████████████████████| 864/864 [00:05<00:00, 170.22it/s]\n",
      "CVM - zara1_vel_modified: 100%|██████████████████████████████████████████████████████████████| 864/864 [00:05<00:00, 171.04it/s]\n",
      "Ours - zara2_vel_modified: 100%|████████████████████████████████████████████████████████████| 1052/1052 [06:11<00:00,  2.83it/s]\n",
      "CVM - zara2_vel_modified: 100%|█████████████████████████████████████████████████████████████| 1052/1052 [00:20<00:00, 52.28it/s]\n",
      "CVM - zara2_vel_modified: 100%|█████████████████████████████████████████████████████████████| 1052/1052 [00:18<00:00, 56.93it/s]\n",
      "CVM - zara2_vel_modified: 100%|█████████████████████████████████████████████████████████████| 1052/1052 [00:15<00:00, 69.20it/s]\n",
      "CVM - zara2_vel_modified: 100%|█████████████████████████████████████████████████████████████| 1052/1052 [00:15<00:00, 69.11it/s]\n"
     ]
    }
   ],
   "source": [
    "eth_params = {\n",
    "    'NOISE': 0.0, \n",
    "    'NO_OF_TRAJECTORIES': 500, \n",
    "    'CONST_VEL_MODEL_PROB': 0.5, \n",
    "    'STOP_PROB': 0.025, \n",
    "    'DISCOUNT_AVG_PROB': 1.0, \n",
    "    'DISCOUNT_LOWER_BOUND': 0.1, \n",
    "    'VELOCITY_CHANGE_PROB': 0.1,\n",
    "    'VELOCITY_CHANGE_NOISE': 0.3, \n",
    "    'ANGLE_CHANGE_PROB': 0.1, \n",
    "    'ANGLE_CHANGE_NOISE': 1, \n",
    "    'GROUP_PERCENTAGES': [0.1], \n",
    "    'GROUP_CLUSTER_COUNT': [1]\n",
    "}\n",
    "\n",
    "hotel_params = {\n",
    "    'NOISE': 0.0, \n",
    "    'NO_OF_TRAJECTORIES': 500, \n",
    "    'CONST_VEL_MODEL_PROB': 0.5, \n",
    "    'STOP_PROB': 0.05, \n",
    "    'DISCOUNT_AVG_PROB': 1.0, \n",
    "    'DISCOUNT_LOWER_BOUND': 0.1, \n",
    "    'VELOCITY_CHANGE_PROB': 0.1,\n",
    "    'VELOCITY_CHANGE_NOISE': 0.3, \n",
    "    'ANGLE_CHANGE_PROB': 0.25, \n",
    "    'ANGLE_CHANGE_NOISE': 3, \n",
    "    'GROUP_PERCENTAGES': [0.1], \n",
    "    'GROUP_CLUSTER_COUNT': [1]\n",
    "}\n",
    "\n",
    "univ_params = {\n",
    "    'NOISE': 0.005, \n",
    "    'NO_OF_TRAJECTORIES': 500, \n",
    "    'CONST_VEL_MODEL_PROB': 0.5, \n",
    "    'STOP_PROB': 0.05, \n",
    "    'DISCOUNT_AVG_PROB': 1.0, \n",
    "    'DISCOUNT_LOWER_BOUND': 0.1, \n",
    "    'VELOCITY_CHANGE_PROB': 0.15,\n",
    "    'VELOCITY_CHANGE_NOISE': 0.15, \n",
    "    'ANGLE_CHANGE_PROB': 0.2, \n",
    "    'ANGLE_CHANGE_NOISE': 3, \n",
    "    'GROUP_PERCENTAGES': [0.1], \n",
    "    'GROUP_CLUSTER_COUNT': [1]\n",
    "}\n",
    "\n",
    "zara1_params = {\n",
    "    'NOISE': 0.0, \n",
    "    'NO_OF_TRAJECTORIES': 500, \n",
    "    'CONST_VEL_MODEL_PROB': 0.5, \n",
    "    'STOP_PROB': 0.05, \n",
    "    'DISCOUNT_AVG_PROB': 1.0, \n",
    "    'DISCOUNT_LOWER_BOUND': 0.15, \n",
    "    'VELOCITY_CHANGE_PROB': 0.05,\n",
    "    'VELOCITY_CHANGE_NOISE': 0.2, \n",
    "    'ANGLE_CHANGE_PROB': 0.25, \n",
    "    'ANGLE_CHANGE_NOISE': 1, \n",
    "    'GROUP_PERCENTAGES': [0.1], \n",
    "    'GROUP_CLUSTER_COUNT': [1]\n",
    "}\n",
    "\n",
    "zara2_params = {\n",
    "    'NOISE': 0.0, \n",
    "    'NO_OF_TRAJECTORIES': 500, \n",
    "    'CONST_VEL_MODEL_PROB': 0.5, \n",
    "    'STOP_PROB': 0.05, \n",
    "    'DISCOUNT_AVG_PROB': 1.0, \n",
    "    'DISCOUNT_LOWER_BOUND': 0.1, \n",
    "    'VELOCITY_CHANGE_PROB': 0.05,\n",
    "    'VELOCITY_CHANGE_NOISE': 0.3, \n",
    "    'ANGLE_CHANGE_PROB': 0.2, \n",
    "    'ANGLE_CHANGE_NOISE': 3, \n",
    "    'GROUP_PERCENTAGES': [0.1], \n",
    "    'GROUP_CLUSTER_COUNT': [1]\n",
    "}\n",
    "\n",
    "our_method_params = [eth_params, hotel_params, univ_params, zara1_params, zara2_params]\n",
    "\n",
    "datasets = [\n",
    "    ['eth/test/biwi_eth.txt'], \n",
    "    ['hotel/test/biwi_hotel.txt'], \n",
    "    ['univ/test/students001.txt', 'univ/test/students003.txt'],\n",
    "    ['zara1/test/crowds_zara01.txt'], \n",
    "    ['zara2/test/crowds_zara02.txt'],\n",
    "]\n",
    "\n",
    "trajectron_resultset_names = [\n",
    "    'eth_vel', \n",
    "    'hotel_vel',\n",
    "    'univ_vel',\n",
    "    'zara1_vel_modified', \n",
    "    'zara2_vel_modified',\n",
    "]\n",
    "\n",
    "trajectron_ar3_resultset_names = [\n",
    "    'eth_ar3', \n",
    "    'hotel_ar3', \n",
    "    'univ_ar3',\n",
    "    'zara1_ar3', \n",
    "    'zara2_ar3',\n",
    "]\n",
    "\n",
    "res = evaluate_all_datasets(our_method_params, datasets, trajectron_resultset_names, trajectron_ar3_resultset_names, evaluate_most_likely=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b5e26f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ours_results = res[0]\n",
    "trajectron_results = res[1]\n",
    "trajectron_ar3_results = res[2]\n",
    "cvm_long_results = res[3]\n",
    "cvm_short_results = res[4]\n",
    "\n",
    "sgan_results = {\n",
    "    'BEST_OF_20': {\n",
    "        'FDE': [1.52, 1.61, 0.69, 1.26, 0.84], \n",
    "        'ADE': [0.81, 0.72, 0.60, 0.34, 0.42]\n",
    "    }, \n",
    "    'MOST_LIKELY': {\n",
    "        'FDE': [2.21, 2.18, 1.28, 0.91, 1.11], \n",
    "        'ADE': [ 1.13, 1.01, 0.60, 0.42, 0.52]\n",
    "    }\n",
    "}\n",
    "\n",
    "index = [\n",
    "    'ETH', \n",
    "    'Hotel', \n",
    "    'Univ',\n",
    "    'Zara 1', \n",
    "    'Zara 2',\n",
    "    \n",
    "]\n",
    "\n",
    "df_data_most_likely_fde = {\n",
    "    'CVM (8pt history)' : pd.Series(cvm_long_results['MOST_LIKELY']['FDE'], index = index),\n",
    "    'CVM (2pt history)' : pd.Series(cvm_short_results['MOST_LIKELY']['FDE'], index = index),\n",
    "    'Social-GAN': pd.Series(sgan_results['MOST_LIKELY']['FDE'], index = index),\n",
    "    'Trajectron++' : pd.Series(trajectron_results['MOST_LIKELY']['FDE'], index = index),\n",
    "    #'Trajectron++ AR3' : pd.Series(trajectron_ar3_results['MOST_LIKELY']['FDE'], index = index),\n",
    "    'Ours': pd.Series(ours_results['MOST_LIKELY']['FDE'], index = index)\n",
    "}\n",
    "\n",
    "df_most_likely_fde = pd.DataFrame(df_data_most_likely_fde)\n",
    "df_most_likely_fde.loc['Average'] = df_most_likely_fde.mean()\n",
    "\n",
    "df_data_most_likely_ade = {\n",
    "    'CVM (8pt history)' : pd.Series(cvm_long_results['MOST_LIKELY']['ADE'], index = index),\n",
    "    'CVM (2pt history)' : pd.Series(cvm_short_results['MOST_LIKELY']['ADE'], index = index),\n",
    "    'Social-GAN': pd.Series(sgan_results['MOST_LIKELY']['ADE'], index = index),\n",
    "    'Trajectron++' : pd.Series(trajectron_results['MOST_LIKELY']['ADE'], index = index),\n",
    "    #'Trajectron++ AR3' : pd.Series(trajectron_ar3_results['MOST_LIKELY']['ADE'], index = index),\n",
    "    'Ours': pd.Series(ours_results['MOST_LIKELY']['ADE'], index = index)\n",
    "}\n",
    "\n",
    "df_most_likely_ade = pd.DataFrame(df_data_most_likely_ade)\n",
    "df_most_likely_ade.loc['Average'] = df_most_likely_ade.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9daaa9cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a7bbf_row0_col3, #T_a7bbf_row1_col4, #T_a7bbf_row2_col4, #T_a7bbf_row3_col3, #T_a7bbf_row4_col3, #T_a7bbf_row5_col3 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a7bbf_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >CVM (8pt history)</th>\n",
       "      <th class=\"col_heading level0 col1\" >CVM (2pt history)</th>\n",
       "      <th class=\"col_heading level0 col2\" >Social-GAN</th>\n",
       "      <th class=\"col_heading level0 col3\" >Trajectron++</th>\n",
       "      <th class=\"col_heading level0 col4\" >Ours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a7bbf_level0_row0\" class=\"row_heading level0 row0\" >ETH</th>\n",
       "      <td id=\"T_a7bbf_row0_col0\" class=\"data row0 col0\" >2.303</td>\n",
       "      <td id=\"T_a7bbf_row0_col1\" class=\"data row0 col1\" >2.282</td>\n",
       "      <td id=\"T_a7bbf_row0_col2\" class=\"data row0 col2\" >2.210</td>\n",
       "      <td id=\"T_a7bbf_row0_col3\" class=\"data row0 col3\" >1.615</td>\n",
       "      <td id=\"T_a7bbf_row0_col4\" class=\"data row0 col4\" >2.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a7bbf_level0_row1\" class=\"row_heading level0 row1\" >Hotel</th>\n",
       "      <td id=\"T_a7bbf_row1_col0\" class=\"data row1 col0\" >0.462</td>\n",
       "      <td id=\"T_a7bbf_row1_col1\" class=\"data row1 col1\" >0.614</td>\n",
       "      <td id=\"T_a7bbf_row1_col2\" class=\"data row1 col2\" >2.180</td>\n",
       "      <td id=\"T_a7bbf_row1_col3\" class=\"data row1 col3\" >0.499</td>\n",
       "      <td id=\"T_a7bbf_row1_col4\" class=\"data row1 col4\" >0.444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a7bbf_level0_row2\" class=\"row_heading level0 row2\" >Univ</th>\n",
       "      <td id=\"T_a7bbf_row2_col0\" class=\"data row2 col0\" >1.576</td>\n",
       "      <td id=\"T_a7bbf_row2_col1\" class=\"data row2 col1\" >1.369</td>\n",
       "      <td id=\"T_a7bbf_row2_col2\" class=\"data row2 col2\" >1.280</td>\n",
       "      <td id=\"T_a7bbf_row2_col3\" class=\"data row2 col3\" >1.205</td>\n",
       "      <td id=\"T_a7bbf_row2_col4\" class=\"data row2 col4\" >1.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a7bbf_level0_row3\" class=\"row_heading level0 row3\" >Zara 1</th>\n",
       "      <td id=\"T_a7bbf_row3_col0\" class=\"data row3 col0\" >1.132</td>\n",
       "      <td id=\"T_a7bbf_row3_col1\" class=\"data row3 col1\" >0.952</td>\n",
       "      <td id=\"T_a7bbf_row3_col2\" class=\"data row3 col2\" >0.910</td>\n",
       "      <td id=\"T_a7bbf_row3_col3\" class=\"data row3 col3\" >0.770</td>\n",
       "      <td id=\"T_a7bbf_row3_col4\" class=\"data row3 col4\" >1.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a7bbf_level0_row4\" class=\"row_heading level0 row4\" >Zara 2</th>\n",
       "      <td id=\"T_a7bbf_row4_col0\" class=\"data row4 col0\" >0.860</td>\n",
       "      <td id=\"T_a7bbf_row4_col1\" class=\"data row4 col1\" >0.724</td>\n",
       "      <td id=\"T_a7bbf_row4_col2\" class=\"data row4 col2\" >1.110</td>\n",
       "      <td id=\"T_a7bbf_row4_col3\" class=\"data row4 col3\" >0.589</td>\n",
       "      <td id=\"T_a7bbf_row4_col4\" class=\"data row4 col4\" >0.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a7bbf_level0_row5\" class=\"row_heading level0 row5\" >Average</th>\n",
       "      <td id=\"T_a7bbf_row5_col0\" class=\"data row5 col0\" >1.267</td>\n",
       "      <td id=\"T_a7bbf_row5_col1\" class=\"data row5 col1\" >1.188</td>\n",
       "      <td id=\"T_a7bbf_row5_col2\" class=\"data row5 col2\" >1.538</td>\n",
       "      <td id=\"T_a7bbf_row5_col3\" class=\"data row5 col3\" >0.936</td>\n",
       "      <td id=\"T_a7bbf_row5_col4\" class=\"data row5 col4\" >1.092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x135b2c100>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_most_likely_fde.style.highlight_min(color = 'lightgreen', axis = 1).format(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b3c045d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c034b_row0_col3, #T_c034b_row1_col3, #T_c034b_row2_col3, #T_c034b_row3_col3, #T_c034b_row4_col3, #T_c034b_row5_col3 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c034b_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >CVM (8pt history)</th>\n",
       "      <th class=\"col_heading level0 col1\" >CVM (2pt history)</th>\n",
       "      <th class=\"col_heading level0 col2\" >Social-GAN</th>\n",
       "      <th class=\"col_heading level0 col3\" >Trajectron++</th>\n",
       "      <th class=\"col_heading level0 col4\" >Ours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c034b_level0_row0\" class=\"row_heading level0 row0\" >ETH</th>\n",
       "      <td id=\"T_c034b_row0_col0\" class=\"data row0 col0\" >1.102</td>\n",
       "      <td id=\"T_c034b_row0_col1\" class=\"data row0 col1\" >1.075</td>\n",
       "      <td id=\"T_c034b_row0_col2\" class=\"data row0 col2\" >1.130</td>\n",
       "      <td id=\"T_c034b_row0_col3\" class=\"data row0 col3\" >0.695</td>\n",
       "      <td id=\"T_c034b_row0_col4\" class=\"data row0 col4\" >0.981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c034b_level0_row1\" class=\"row_heading level0 row1\" >Hotel</th>\n",
       "      <td id=\"T_c034b_row1_col0\" class=\"data row1 col0\" >0.243</td>\n",
       "      <td id=\"T_c034b_row1_col1\" class=\"data row1 col1\" >0.319</td>\n",
       "      <td id=\"T_c034b_row1_col2\" class=\"data row1 col2\" >1.010</td>\n",
       "      <td id=\"T_c034b_row1_col3\" class=\"data row1 col3\" >0.224</td>\n",
       "      <td id=\"T_c034b_row1_col4\" class=\"data row1 col4\" >0.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c034b_level0_row2\" class=\"row_heading level0 row2\" >Univ</th>\n",
       "      <td id=\"T_c034b_row2_col0\" class=\"data row2 col0\" >0.781</td>\n",
       "      <td id=\"T_c034b_row2_col1\" class=\"data row2 col1\" >0.618</td>\n",
       "      <td id=\"T_c034b_row2_col2\" class=\"data row2 col2\" >0.600</td>\n",
       "      <td id=\"T_c034b_row2_col3\" class=\"data row2 col3\" >0.468</td>\n",
       "      <td id=\"T_c034b_row2_col4\" class=\"data row2 col4\" >0.561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c034b_level0_row3\" class=\"row_heading level0 row3\" >Zara 1</th>\n",
       "      <td id=\"T_c034b_row3_col0\" class=\"data row3 col0\" >0.552</td>\n",
       "      <td id=\"T_c034b_row3_col1\" class=\"data row3 col1\" >0.427</td>\n",
       "      <td id=\"T_c034b_row3_col2\" class=\"data row3 col2\" >0.420</td>\n",
       "      <td id=\"T_c034b_row3_col3\" class=\"data row3 col3\" >0.297</td>\n",
       "      <td id=\"T_c034b_row3_col4\" class=\"data row3 col4\" >0.476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c034b_level0_row4\" class=\"row_heading level0 row4\" >Zara 2</th>\n",
       "      <td id=\"T_c034b_row4_col0\" class=\"data row4 col0\" >0.421</td>\n",
       "      <td id=\"T_c034b_row4_col1\" class=\"data row4 col1\" >0.324</td>\n",
       "      <td id=\"T_c034b_row4_col2\" class=\"data row4 col2\" >0.520</td>\n",
       "      <td id=\"T_c034b_row4_col3\" class=\"data row4 col3\" >0.227</td>\n",
       "      <td id=\"T_c034b_row4_col4\" class=\"data row4 col4\" >0.352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c034b_level0_row5\" class=\"row_heading level0 row5\" >Average</th>\n",
       "      <td id=\"T_c034b_row5_col0\" class=\"data row5 col0\" >0.620</td>\n",
       "      <td id=\"T_c034b_row5_col1\" class=\"data row5 col1\" >0.553</td>\n",
       "      <td id=\"T_c034b_row5_col2\" class=\"data row5 col2\" >0.736</td>\n",
       "      <td id=\"T_c034b_row5_col3\" class=\"data row5 col3\" >0.382</td>\n",
       "      <td id=\"T_c034b_row5_col4\" class=\"data row5 col4\" >0.521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x135b2c0a0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_most_likely_ade.style.highlight_min(color = 'lightgreen', axis = 1).format(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc28360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108cb862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
