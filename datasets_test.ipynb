{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8e53c794-6b8c-4df3-801a-3d578061b913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(os.getcwd()) + '/OpenTraj/opentraj/') # Anaconda python can't find the toolkit path without this for some reason\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185a6f2a-caf4-4356-a837-1d4cc0e07a7c",
   "metadata": {},
   "source": [
    "### Edinburgh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ceba26-71ec-44b6-8c08-7a7cce9a68e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit.loaders.loader_edinburgh import load_edinburgh\n",
    "opentraj_root = './OpenTraj/'\n",
    "selected_day = '01Sep' # 3 days of data in total, ['01Jul', '01Aug', '01Sep']\n",
    "edinburgh_path = os.path.join(opentraj_root, 'datasets/Edinburgh/annotations', 'tracks.%s.txt' % selected_day)\n",
    "traj_dataset = load_edinburgh(edinburgh_path, title=\"Edinburgh\", \n",
    "                              use_kalman=False, scene_id=selected_day, sampling_rate=9)\n",
    "data = traj_dataset.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a004f1-c662-4946-a377-02e8ec4b3041",
   "metadata": {},
   "source": [
    "### ETH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "42284d23-ae61-4298-95d9-b85455d1913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit.loaders.loader_eth import load_eth\n",
    "traj_dataset = load_eth(\"OpenTraj/datasets/ETH/seq_eth/obsmat.txt\", sampling_rate=4)\n",
    "data = traj_dataset.data\n",
    "\n",
    "num_steps=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1c361bcf-40a9-4191-8cbd-ac7402bee120",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['label']=='pedestrian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9f99adc8-d72f-4db6-949b-34dd0fa23f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_ids = data.agent_id.unique()\n",
    "for agent_id in agent_ids:\n",
    "    if len(data[data.agent_id == agent_id]) < 2 * num_steps:\n",
    "        data = data[data.agent_id != agent_id]\n",
    "agent_ids = data.agent_id.unique()\n",
    "\n",
    "\n",
    "for agent_id in agent_ids:\n",
    "    first_x = data[data.agent_id == agent_id]['pos_x'].iloc[0]\n",
    "    first_y = data[data.agent_id == agent_id]['pos_y'].iloc[0]\n",
    "\n",
    "    # 'Normalize' the data so that all trajectories will begin at x=0, y=0\n",
    "    data.loc[data.agent_id == agent_id, 'pos_x'] = data[data.agent_id == agent_id]['pos_x'] - first_x\n",
    "    data.loc[data.agent_id == agent_id, 'pos_y'] = data[data.agent_id == agent_id]['pos_y'] - first_y\n",
    "    # Calculate own velocities so that they don't depend on sampling rate\n",
    "    data.loc[data.agent_id == agent_id, 'vel_x'] = data[data.agent_id == agent_id]['pos_x'].diff()\n",
    "    data.loc[data.agent_id == agent_id, 'vel_y'] = data[data.agent_id == agent_id]['pos_y'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4905f7-a399-49ea-a7ce-419fff389ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
